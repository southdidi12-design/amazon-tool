import streamlit as st
import pandas as pd
import requests
import json
import os
from datetime import datetime

# === 1. å…¨å±€é…ç½® ===
st.set_page_config(
    page_title="Amazon AI è®­ç»ƒå¸ˆ (v5.1 æ‡’äººç‰ˆ)", 
    layout="wide", 
    page_icon="ğŸ§ ",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .main { background-color: #f8f9fa; }
    div[data-testid="stMetric"] { background-color: white; border: 1px solid #ddd; padding: 10px; border-radius: 8px; }
    .stTabs [data-baseweb="tab-list"] { gap: 8px; }
    .stButton>button { width: 100%; border-radius: 4px; }
</style>
""", unsafe_allow_html=True)

# === 2. æ ¸å¿ƒï¼šAI è‡ªåŠ¨æ€è€ƒå¹¶è®°å½• (CoT ç”Ÿæˆå™¨) ===
DATA_FILE = "deepseek_cot_data.jsonl"

def generate_and_save_ai_thought(api_key, term, spend, clicks, orders, user_intent):
    """
    1. è°ƒç”¨ DeepSeek ç”Ÿæˆæ·±åº¦æ€è€ƒ
    2. å°†æ€è€ƒè¿‡ç¨‹ + ç»“è®º ä¿å­˜ä¸ºè®­ç»ƒæ•°æ®
    """
    if not api_key:
        st.error("âŒ éœ€è¦ API Key æ‰èƒ½ç”Ÿæˆ AI æ€è€ƒï¼")
        return None

    # 1. æ„é€ å‘ç»™ AI çš„æç¤ºè¯ (Prompt)
    prompt = f"""
    æˆ‘æ˜¯äºšé©¬é€Šè¿è¥ã€‚äº§å“æ˜¯ Makeup Mirrorã€‚
    è¯·åˆ†ææœç´¢è¯ï¼š"{term}"ã€‚
    æ•°æ®ï¼šèŠ±è´¹ ${spend}, ç‚¹å‡» {clicks}, è®¢å• {orders}ã€‚
    
    è¯·è¾“å‡ºä¸€ä¸ª JSON æ ¼å¼çš„å›ç­”ï¼ŒåŒ…å«ä¸¤ä¸ªå­—æ®µï¼š
    1. "reasoning": è¯¦ç»†çš„åˆ†ææ€è€ƒè¿‡ç¨‹ï¼ˆå…ˆåˆ†ææ•°æ®ï¼Œå†åˆ†æè¯­ä¹‰ç›¸å…³æ€§ï¼Œæœ€åå¾—å‡ºç»“è®ºï¼‰ã€‚
    2. "action": å»ºè®®æ“ä½œï¼ˆNegative Exact / Negative Phrase / Keep / Increase Bidï¼‰ã€‚
    
    æˆ‘çš„é¢„åˆ¤å€¾å‘æ˜¯ï¼š{user_intent} (è¯·å‚è€ƒæˆ‘çš„å€¾å‘ï¼Œä½†å¦‚æœæœ‰ç†æœ‰æ®å¯ä»¥åé©³)
    """

    try:
        # 2. è°ƒç”¨ API
        with st.spinner(f"ğŸ§  AI æ­£åœ¨æ·±åº¦åˆ†æ '{term}' ..."):
            res = requests.post(
                "https://api.deepseek.com/chat/completions",
                headers={"Authorization": f"Bearer {api_key}"},
                json={
                    "model": "deepseek-chat",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.7, 
                    "response_format": {"type": "json_object"} 
                }
            )
            
            if res.status_code == 200:
                ai_content = res.json()['choices'][0]['message']['content']
                ai_json = json.loads(ai_content)
                
                reasoning = ai_json.get("reasoning", "AI æœªæä¾›è¯¦æƒ…")
                action = ai_json.get("action", "Unknown")

                # 3. æ„é€ æˆè®­ç»ƒæ•°æ®æ ¼å¼
                train_data = {
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç²¾é€š Amazon PPC çš„ä¸“å®¶ï¼Œä½ çš„å›ç­”å¿…é¡»åŒ…å«æ·±åº¦çš„æ•°æ®åˆ†æå’Œé€»è¾‘æ¨ç†ã€‚"},
                        {"role": "user", "content": f"åˆ†æè¯: {term}, èŠ±è´¹: ${spend}, ç‚¹å‡»: {clicks}, è®¢å•: {orders}"},
                        {"role": "assistant", "content": f"åˆ†æé€»è¾‘ï¼š{reasoning}\n\nå»ºè®®æ“ä½œï¼šã€{action}ã€‘"}
                    ]
                }

                # 4. ä¿å­˜æ–‡ä»¶
                with open(DATA_FILE, "a", encoding="utf-8") as f:
                    f.write(json.dumps(train_data, ensure_ascii=False) + "\n")
                
                st.toast(f"âœ… å·²ä¿å­˜æ€è€ƒè·¯å¾„ï¼\nAI è§‚ç‚¹: {reasoning[:30]}...")
                return reasoning
            else:
                st.error(f"API æŠ¥é”™: {res.text}")
    except Exception as e:
        st.error(f"ç½‘ç»œé”™è¯¯: {e}")

# === 3. ä¾§è¾¹æ  ===
st.sidebar.title("ğŸ§  æ§åˆ¶å° v5.1")

# ğŸ”¥ğŸ”¥ğŸ”¥ ä½ çš„ Key å·²ç»é¢„å¡«åœ¨è¿™é‡Œäº† ğŸ”¥ğŸ”¥ğŸ”¥
default_key = "sk-55cc3f56742f4e43be099c9489e02911"
deepseek_key = st.sidebar.text_input("ğŸ”‘ DeepSeek Key", value=default_key, type="password")

product_name = st.sidebar.text_input("ğŸ“¦ äº§å“åç§°", value="Makeup Mirror")

st.sidebar.markdown("---")
# è®­ç»ƒæ•°æ®ä¸‹è½½åŒº
if os.path.exists(DATA_FILE):
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        count = sum(1 for _ in f)
    st.sidebar.metric("ğŸ“š å·²ç§¯ç´¯ CoT æ•™æ", f"{count} æ¡")
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        st.sidebar.download_button("ğŸ“¥ ä¸‹è½½å¸¦æ€è€ƒçš„æ•°æ®", f, file_name="deepseek_cot_finetune.jsonl")
else:
    st.sidebar.info("æš‚æ— æ•°æ®ï¼Œå¿«å»è®© AI æ€è€ƒå§ï¼")

# === 4. ä¸»ç•Œé¢ ===
st.title("ğŸ§  Amazon AI è®­ç»ƒå¸ˆ (v5.1 æ‡’äººç‰ˆ)")
st.caption("ğŸš€ å†…ç½® API Key | ç‚¹å‡»æŒ‰é’®ç”Ÿæˆæ·±åº¦åˆ†æ | è‡ªåŠ¨ç§¯ç´¯é«˜è´¨é‡æ•™æ")

c1, c2 = st.columns(2)
with c1:
    file_bulk = st.file_uploader("ğŸ“‚ Bulk è¡¨æ ¼ (å›¾è¡¨)", type=['xlsx', 'csv'], key="bulk")
with c2:
    file_term = st.file_uploader("ğŸ“‚ Search Term (è®­ç»ƒæ ¸å¿ƒ)", type=['xlsx', 'csv'], key="term")

# æ•°æ®è¯»å–å·¥å…·
def load_data(file, ftype):
    if not file: return pd.DataFrame()
    try:
        if file.name.endswith('.csv'): df = pd.read_csv(file)
        else:
            if ftype == 'bulk':
                dfs = pd.read_excel(file, sheet_name=None, engine='openpyxl')
                for _, d in dfs.items():
                    if d.astype(str).apply(lambda x: x.str.contains('Keyword|å…³é”®è¯', case=False)).any().any(): return d
                return pd.DataFrame()
            else: df = pd.read_excel(file, engine='openpyxl')
        return df
    except: return pd.DataFrame()

df_bulk = load_data(file_bulk, 'bulk')
df_term = load_data(file_term, 'term')
if not df_bulk.empty: df_bulk.columns = df_bulk.columns.astype(str).str.strip()
if not df_term.empty: df_term.columns = df_term.columns.astype(str).str.strip()

# === 5. åŠŸèƒ½åŒº ===
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ§  AI è‡ªåŠ¨æ ‡æ³¨ (æ ¸å¿ƒ)", "ğŸ“ˆ çœ‹æ¿", "ğŸ’° ç«ä»·", "ğŸ† é»„é‡‘è¯"])

# --- Tab 1: AI è‡ªåŠ¨æ ‡æ³¨ (Core) ---
with tab1:
    st.subheader("ğŸ§  æ€ç»´é“¾ (CoT) æ•°æ®ç”Ÿäº§è½¦é—´")
    st.info("ğŸ’¡ ç°åœ¨ä¸éœ€è¦è¾“ Key äº†ï¼ç›´æ¥ç‚¹å‡»ä¸‹é¢çš„æŒ‰é’®ï¼ŒAI å°±ä¼šå¼€å§‹å·¥ä½œã€‚")
    
    if not df_term.empty:
        st_cols = {
            'term': next((c for c in df_term.columns if c in ["å®¢æˆ·æœç´¢è¯", "Search Term", "Customer Search Term"]), None),
            'spend': next((c for c in df_term.columns if c in ["èŠ±è´¹", "Spend"]), None),
            'orders': next((c for c in df_term.columns if c in ["7å¤©æ€»è®¢å•æ•°(#)", "è®¢å•æ•°é‡", "Orders"]), None),
            'clicks': next((c for c in df_term.columns if c in ["ç‚¹å‡»é‡", "Clicks"]), None),
        }
        
        if st_cols['spend'] and st_cols['term']:
            for c in [st_cols['spend'], st_cols['clicks'], st_cols['orders']]:
                if c: df_term[c] = pd.to_numeric(df_term[c], errors='coerce').fillna(0)
            
            # ç­›é€‰ï¼š0è®¢å• & æœ‰èŠ±è´¹
            mask = (df_term[st_cols['orders']] == 0) & (df_term[st_cols['spend']] > 0)
            review_df = df_term[mask].sort_values(by=st_cols['spend'], ascending=False).head(20)
            
            if not review_df.empty:
                for index, row in review_df.iterrows():
                    with st.expander(f"ğŸ“ {row[st_cols['term']]} (èŠ±è´¹: ${row[st_cols['spend']]:.2f})", expanded=True):
                        col1, col2, col3 = st.columns([1, 1, 3])
                        
                        term = row[st_cols['term']]
                        sp = row[st_cols['spend']]
                        cl = row[st_cols['clicks']]
                        od = row[st_cols['orders']]
                        
                        # æŒ‰é’®é€»è¾‘ï¼šä½ ç»™ä¸ªå¤§æ–¹å‘ï¼ŒAI è´Ÿè´£å†™è¯¦ç»†é€»è¾‘
                        with col1:
                            if st.button("âŒ ç”Ÿæˆâ€˜å¦å®šâ€™é€»è¾‘", key=f"gen_neg_{index}", type="primary"):
                                reason = generate_and_save_ai_thought(deepseek_key, term, sp, cl, od, "Negative")
                                if reason: st.success(f"å·²å­˜é€»è¾‘: {reason}")
                        
                        with col2:
                            if st.button("âœ¨ ç”Ÿæˆâ€˜ä¿ç•™â€™é€»è¾‘", key=f"gen_keep_{index}"):
                                reason = generate_and_save_ai_thought(deepseek_key, term, sp, cl, od, "Keep")
                                if reason: st.success(f"å·²å­˜é€»è¾‘: {reason}")
                                
                        with col3:
                            st.caption("ğŸ‘ˆ ç‚¹å‡»æŒ‰é’®ï¼ŒDeepSeek å°±ä¼šå¸®ä½ å†™å‡ºåˆ†æè¿‡ç¨‹ï¼Œå¹¶å­˜å…¥åå°ã€‚")

            else: st.success("æ²¡æœ‰å‘ç°æ˜æ˜¾çš„æµªè´¹è¯ã€‚")
        else: st.error("ç¼ºå°‘å¿…è¦åˆ—")
    else: st.info("è¯·å…ˆä¸Šä¼  Search Term è¡¨æ ¼")

# --- Tab 2: çœ‹æ¿ ---
with tab2:
    st.subheader("ğŸ“ˆ è´¦æˆ·é€è§†")
    if not df_bulk.empty and 'df_kws' in locals():
        # é¢„å¤„ç† Bulk
        bk_cols = {
            'entity': next((c for c in df_bulk.columns if c in ["å®ä½“å±‚çº§", "Record Type"]), None),
            'kw': next((c for c in df_bulk.columns if c in ["å…³é”®è¯æ–‡æœ¬", "Keyword Text"]), None),
            'bid': next((c for c in df_bulk.columns if c in ["ç«ä»·", "Keyword Bid"]), None),
            'spend': next((c for c in df_bulk.columns if c in ["èŠ±è´¹", "Spend"]), None),
            'sales': next((c for c in df_bulk.columns if c in ["é”€é‡", "Sales"]), None),
            'orders': next((c for c in df_bulk.columns if c in ["è®¢å•æ•°é‡", "Orders"]), None),
            'clicks': next((c for c in df_bulk.columns if c in ["ç‚¹å‡»é‡", "Clicks"]), None),
        }
        if bk_cols['entity'] and bk_cols['kw']:
            df_kws = df_bulk[df_bulk[bk_cols['entity']].astype(str).str.contains('Keyword|å…³é”®è¯', case=False, na=False)].copy()
            for c in [bk_cols['spend'], bk_cols['sales'], bk_cols['orders'], bk_cols['clicks'], bk_cols['bid']]:
                if c: df_kws[c] = pd.to_numeric(df_kws[c], errors='coerce').fillna(0)
            if bk_cols['spend'] and bk_cols['sales']:
                df_kws['ACoS'] = df_kws.apply(lambda x: x[bk_cols['spend']]/x[bk_cols['sales']] if x[bk_cols['sales']]>0 else 0, axis=1)

            st.scatter_chart(df_kws[df_kws[bk_cols['spend']]>0], x=bk_cols['spend'], y=bk_cols['sales'], size=bk_cols['clicks'], color='ACoS', height=400)
    else: st.info("è¯·ä¸Šä¼  Bulk è¡¨æ ¼ã€‚")

# --- Tab 3/4 ---
with tab3:
    st.subheader("ğŸ“‰ ç«ä»·ä¼˜åŒ–")
    if not df_bulk.empty and 'df_kws' in locals():
        target_acos = 0.3 # é»˜è®¤å€¼
        bad = df_kws[(df_kws[bk_cols['orders']]>0) & (df_kws['ACoS']>target_acos)].head(20)
        if not bad.empty: st.dataframe(bad[[bk_cols['kw'], 'ACoS', bk_cols['spend']]], use_container_width=True)
    else: st.info("è¯·ä¸Šä¼  Bulk è¡¨æ ¼")

with tab4:
    st.subheader("ğŸ† é»„é‡‘æŒ–æ˜")
    if not df_bulk.empty and 'df_kws' in locals():
        gold = df_kws[(df_kws[bk_cols['orders']]>=2) & (df_kws['ACoS']<0.2)].head(20)
        if not gold.empty: st.dataframe(gold[[bk_cols['kw'], 'ACoS', bk_cols['sales']]], use_container_width=True)
    else: st.info("è¯·ä¸Šä¼  Bulk è¡¨æ ¼")