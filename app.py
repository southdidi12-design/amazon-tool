import streamlit as st
import pandas as pd
import requests
import json
import os
from datetime import datetime

# === 1. å…¨å±€é…ç½® ===
st.set_page_config(
    page_title="Amazon AI æŒ‡æŒ¥å®˜ (v5.14 å®Œå…¨ä½“)", 
    layout="wide", 
    page_icon="ğŸ’",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .main { background-color: #f8f9fa; }
    div[data-testid="stMetric"] { background-color: white; border: 1px solid #ddd; padding: 10px; border-radius: 8px; }
    .stTabs [data-baseweb="tab-list"] { gap: 8px; }
    .stButton>button { width: 100%; border-radius: 4px; }
    .ai-thought { background-color: #fff; padding: 10px; border: 1px solid #eee; border-radius: 5px; font-size: 13px; margin-top: 5px;}
    
    /* ASIN é“¾æ¥æ ·å¼ */
    .asin-link { 
        font-size: 15px; 
        color: #d93025; 
        font-weight: bold; 
        text-decoration: none;
        padding-bottom: 5px;
        display: block;
    }
</style>
""", unsafe_allow_html=True)

# === 2. æ ¸å¿ƒé€»è¾‘ ===
DATA_FILE = "deepseek_cot_data.jsonl"

def save_manual_label(term, spend, clicks, orders, action):
    train_data = {
        "messages": [
            {"role": "system", "content": "PPCä¸“å®¶"},
            {"role": "user", "content": f"è¯:{term}, è´¹:{spend}, å•:{orders}"},
            {"role": "assistant", "content": f"ã€äººå·¥è£å†³ã€‘\n-> æ“ä½œ: {action}"}
        ]
    }
    with open(DATA_FILE, "a", encoding="utf-8") as f:
        f.write(json.dumps(train_data, ensure_ascii=False) + "\n")
    st.toast(f"âš¡ å·²å¤„ç†: {term}")

def generate_and_save_ai_thought(api_key, term, spend, clicks, orders, user_intent):
    if not api_key: return None
    cpc = spend / clicks if clicks > 0 else 0
    prompt = f"""
    åˆ†æå¸ˆè§’è‰²ã€‚äº§å“: Makeup Mirrorã€‚å¯¹è±¡: "{term}"ã€‚
    è¾“å‡º JSON (reasoning, action)ã€‚
    æ•°æ®: èŠ±è´¹${spend}, ç‚¹å‡»{clicks}, CPC ${cpc:.2f}, è®¢å•{orders}ã€‚
    é€»è¾‘: 1.CPC? 2.ç‚¹å‡»é‡æ˜¾è‘—æ€§? 3.æ„å›¾?
    å€¾å‘: {user_intent}ã€‚
    """
    try:
        with st.spinner(f"â³ AI æ€è€ƒä¸­..."):
            res = requests.post(
                "https://api.deepseek.com/chat/completions",
                headers={"Authorization": f"Bearer {api_key}"},
                json={"model": "deepseek-chat", "messages": [{"role": "user", "content": prompt}], "temperature": 0.5, "response_format": {"type": "json_object"}}
            )
            if res.status_code == 200:
                ai_json = json.loads(res.json()['choices'][0]['message']['content'])
                train_data = {
                    "messages": [{"role": "user", "content": f"è¯:{term}"}, {"role": "assistant", "content": f"{ai_json.get('reasoning')}\n-> {ai_json.get('action')}"}]
                }
                with open(DATA_FILE, "a", encoding="utf-8") as f:
                    f.write(json.dumps(train_data, ensure_ascii=False) + "\n")
                return ai_json.get('reasoning')
    except: return None

# === 3. ä¾§è¾¹æ  (è¿™é‡ŒæŠŠè®¾ç½®è£…å›æ¥äº†ï¼) ===
st.sidebar.title("ğŸ’ æ§åˆ¶å° v5.14")
default_key = "sk-55cc3f56742f4e43be099c9489e02911"
deepseek_key = st.sidebar.text_input("ğŸ”‘ DeepSeek Key", value=default_key, type="password")
product_name = st.sidebar.text_input("ğŸ“¦ äº§å“åç§°", value="Makeup Mirror")

st.sidebar.markdown("---")
# ğŸ”¥ğŸ”¥ğŸ”¥ ä½ çš„è®¾ç½®æ»‘å—å›æ¥äº† ğŸ”¥ğŸ”¥ğŸ”¥
with st.sidebar.expander("âš™ï¸ è§„åˆ™è®¾ç½® (å½±å“ç«ä»·/é»„é‡‘è¯)", expanded=True):
    target_acos = st.slider("ğŸ¯ ç›®æ ‡ ACoS", 0.1, 1.0, 0.3, help="é«˜äºè¿™ä¸ªå€¼çš„è¯ä¼šè¢«å»ºè®®é™ä»·")
    gold_acos = st.slider("ğŸ† é»„é‡‘è¯ ACoS ä¸Šé™", 0.1, 1.0, 0.2, help="ä½äºè¿™ä¸ªå€¼çš„è¯è¢«è§†ä¸ºé»„é‡‘è¯")

st.sidebar.markdown("---")
if os.path.exists(DATA_FILE):
    with open(DATA_FILE, "r", encoding="utf-8") as f: count = sum(1 for _ in f)
    st.sidebar.metric("ğŸ“š è®­ç»ƒæ•°æ®", f"{count} æ¡")
    with open(DATA_FILE, "r", encoding="utf-8") as f: st.sidebar.download_button("ğŸ“¥ ä¸‹è½½æ–‡ä»¶", f, file_name="finetune.jsonl")

# === 4. ä¸»ç•Œé¢ ===
st.title("ğŸ’ Amazon AI æŒ‡æŒ¥å®˜ (v5.14 å®Œå…¨ä½“)")
st.caption("âœ… å·¦ä¾§è§„åˆ™è®¾ç½®å·²æ¢å¤ | ASIN è·³è½¬å·²å°±ç»ª | CPC æ•°æ®å·²æ˜¾ç¤º")

c1, c2 = st.columns(2)
with c1:
    file_bulk = st.file_uploader("ğŸ“‚ 1. Bulk è¡¨æ ¼", type=['xlsx', 'csv'], key="bulk")
with c2:
    file_term = st.file_uploader("ğŸ“‚ 2. Search Term è¡¨æ ¼", type=['xlsx', 'csv'], key="term")

# è¯»å–é€»è¾‘
def smart_load_bulk(file):
    if not file: return pd.DataFrame()
    try:
        if file.name.endswith('.csv'): return pd.read_csv(file)
        dfs = pd.read_excel(file, sheet_name=None, engine='openpyxl')
        for sheet_name, df in dfs.items():
            cols = df.columns.astype(str).tolist()
            if any(x in cols for x in ['å®ä½“å±‚çº§', 'Record Type']) and any(x in cols for x in ['å…³é”®è¯æ–‡æœ¬', 'Keyword Text', 'æŠ•æ”¾']):
                st.toast(f"âœ… Bulk å°±ç»ª: {sheet_name}")
                return df
        return pd.DataFrame()
    except: return pd.DataFrame()

df_bulk = smart_load_bulk(file_bulk)

def load_simple(file):
    if not file: return pd.DataFrame()
    try:
        if file.name.endswith('.csv'): return pd.read_csv(file)
        return pd.read_excel(file, engine='openpyxl')
    except: return pd.DataFrame()

df_term = load_simple(file_term)

if not df_bulk.empty: df_bulk.columns = df_bulk.columns.astype(str).str.strip()
if not df_term.empty: df_term.columns = df_term.columns.astype(str).str.strip()

# å…¨å±€é¢„å¤„ç†
bulk_ready = False
df_kws = pd.DataFrame()
bk_cols = {}

if not df_bulk.empty:
    cols = df_bulk.columns
    bk_cols['spend'] = 'èŠ±è´¹'
    bk_cols['sales'] = next((c for c in ['é”€é‡', 'é”€å”®é¢', '7å¤©æ€»é”€å”®é¢', 'Sales'] if c in cols), None)
    bk_cols['clicks'] = 'ç‚¹å‡»é‡'
    bk_cols['entity'] = 'å®ä½“å±‚çº§'
    bk_cols['kw'] = next((c for c in ['å…³é”®è¯æ–‡æœ¬', 'æŠ•æ”¾'] if c in cols), None)
    bk_cols['bid'] = next((c for c in ['ç«ä»·', 'Keyword Bid'] if c in cols), None)
    bk_cols['orders'] = 'è®¢å•æ•°é‡'

    if bk_cols['entity'] and bk_cols['kw'] and bk_cols['sales'] and bk_cols['spend']:
        df_kws = df_bulk[df_bulk[bk_cols['entity']].astype(str).str.contains('Keyword|å…³é”®è¯|Targeting', case=False, na=False)].copy()
        for c in [bk_cols['spend'], bk_cols['sales'], bk_cols['clicks'], bk_cols['bid'], bk_cols['orders']]:
            if c: df_kws[c] = pd.to_numeric(df_kws[c], errors='coerce').fillna(0)
        df_kws['ACoS'] = df_kws.apply(lambda x: x[bk_cols['spend']]/x[bk_cols['sales']] if x[bk_cols['sales']]>0 else 0, axis=1)
        bulk_ready = True

# === 5. åŠŸèƒ½æ ‡ç­¾é¡µ ===
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "âš¡ é€è§†æ¸…æ´—", "ğŸ“ˆ çœ‹æ¿", "ğŸ’° ç«ä»·", "ğŸ† é»„é‡‘", "ğŸ’« å…³è”"
])

# --- Tab 1: å¿«é€Ÿæ¸…æ´— ---
with tab1:
    st.subheader("âš¡ å¿«é€Ÿæ¸…æ´— (ASIN é€è§†ç‰ˆ)")
    
    if not df_term.empty:
        c_term = 'å®¢æˆ·æœç´¢è¯'
        c_spend = 'èŠ±è´¹'
        c_orders = '7å¤©æ€»è®¢å•æ•°(#)'
        c_clicks = 'ç‚¹å‡»é‡'
        
        if c_term in df_term.columns:
            df_term[c_spend] = pd.to_numeric(df_term[c_spend], errors='coerce').fillna(0)
            df_term[c_orders] = pd.to_numeric(df_term[c_orders], errors='coerce').fillna(0)
            df_term[c_clicks] = pd.to_numeric(df_term[c_clicks], errors='coerce').fillna(0)
            
            mask = (df_term[c_orders] == 0) & (df_term[c_spend] > 0)
            review_df = df_term[mask].sort_values(by=c_spend, ascending=False).head(20)
            
            if not review_df.empty:
                for idx, row in review_df.iterrows():
                    term_val = str(row[c_term])
                    spend_val = row[c_spend]
                    clicks_val = row[c_clicks]
                    cpc_val = spend_val / clicks_val if clicks_val > 0 else 0
                    
                    label = f"ğŸ“ {term_val} | ğŸ’¸ ${spend_val:.2f} | ğŸ–±ï¸ {int(clicks_val)}æ¬¡ | CPC ${cpc_val:.2f}"
                    
                    with st.expander(label, expanded=True):
                        # ASIN è·³è½¬
                        if term_val.lower().startswith("b0"):
                            st.markdown(f"ğŸ”— <a href='https://www.amazon.com/dp/{term_val}' target='_blank' class='asin-link'>ğŸ‘‰ ç‚¹å‡»å»äºšé©¬é€Šçœ‹ä¸€çœ¼: {term_val}</a>", unsafe_allow_html=True)
                        
                        c1, c2, c3 = st.columns([1, 1, 3])
                        with c1:
                            if st.button("âš¡ ç¬æ€", key=f"kill_{idx}", type="primary"):
                                save_manual_label(term_val, spend_val, clicks_val, 0, "Negative")
                        with c2:
                            if st.button("ğŸ‘€ ç¬ç•™", key=f"keep_{idx}"):
                                save_manual_label(term_val, spend_val, clicks_val, 0, "Keep")
                        with c3:
                            if st.button("ğŸ¤– é—®AI", key=f"ask_{idx}"):
                                reasoning = generate_and_save_ai_thought(deepseek_key, term_val, spend_val, clicks_val, 0, "Unknown")
                                if reasoning: st.session_state[f"ai_{idx}"] = reasoning
                            if f"ai_{idx}" in st.session_state:
                                st.markdown(f"""<div class="ai-thought">{st.session_state[f"ai_{idx}"]}</div>""", unsafe_allow_html=True)
            else: st.success("æ²¡æœ‰å‘ç°é«˜èŠ±è´¹0è½¬åŒ–çš„è¯ã€‚")
    else: st.info("è¯·ä¸Šä¼  Search Term")

# --- Tab 2: çœ‹æ¿ ---
with tab2:
    st.subheader("ğŸ“ˆ è´¦æˆ·é€è§†")
    if bulk_ready:
        st.scatter_chart(df_kws[df_kws[bk_cols['spend']]>0], x=bk_cols['spend'], y=bk_cols['sales'], size=bk_cols['clicks'], color='ACoS')
    else: st.info("è¯·ä¸Šä¼  Bulk è¡¨æ ¼")

# --- Tab 3: ç«ä»· (ä½¿ç”¨å·¦ä¾§è®¾ç½®çš„ target_acos) ---
with tab3:
    st.subheader(f"ğŸ’° ç«ä»·ä¼˜åŒ– (ç›®æ ‡ ACoS: {target_acos*100}%)")
    if bulk_ready:
        # ç­›é€‰ ACoS > å·¦ä¾§è®¾ç½®å€¼
        bad = df_kws[(df_kws[bk_cols['orders']] > 0) & (df_kws['ACoS'] > target_acos)].sort_values(by='ACoS', ascending=False).head(50)
        
        if not bad.empty:
            show_df = bad[[bk_cols['kw'], bk_cols['bid'], 'ACoS', bk_cols['spend'], bk_cols['sales']]].copy()
            show_df['å»ºè®®ç«ä»·'] = show_df[bk_cols['bid']] * 0.8
            st.dataframe(show_df, column_config={"ACoS": st.column_config.ProgressColumn(format="%.2f", max_value=2)}, use_container_width=True)
        else: st.success(f"å¤ªæ£’äº†ï¼æ‰€æœ‰å‡ºå•è¯çš„ ACoS éƒ½ä½äº {target_acos*100}%ã€‚")
    else: st.info("è¯·ä¸Šä¼  Bulk è¡¨æ ¼")

# --- Tab 4: é»„é‡‘è¯ (ä½¿ç”¨å·¦ä¾§è®¾ç½®çš„ gold_acos) ---
with tab4:
    st.subheader(f"ğŸ† é»„é‡‘è¯æŒ–æ˜ (ACoS < {gold_acos*100}%)")
    if bulk_ready:
        gold_df = df_kws[(df_kws[bk_cols['orders']] >= 2) & (df_kws['ACoS'] > 0) & (df_kws['ACoS'] < gold_acos)].sort_values(by=bk_cols['sales'], ascending=False).head(50)
        if not gold_df.empty:
            show_df = gold_df[[bk_cols['kw'], bk_cols['bid'], 'ACoS', bk_cols['sales']]].copy()
            show_df['å»ºè®®ç«ä»·'] = show_df[bk_cols['bid']] * 1.2
            st.dataframe(show_df, column_config={"ACoS": st.column_config.ProgressColumn(format="%.2f", max_value=0.5)}, use_container_width=True)
        else: st.info(f"æš‚æ— é»„é‡‘è¯ï¼Œè¯•ç€åœ¨å·¦ä¾§è°ƒé«˜ä¸€ç‚¹é˜ˆå€¼ï¼Ÿ")
    else: st.info("è¯·ä¸Šä¼  Bulk è¡¨æ ¼")

# --- Tab 5: å…³è” ---
with tab5:
    st.subheader("ğŸ’« å…³è”åˆ†æ")
    if not df_term.empty:
        c_halo = '7å¤©å†…å…¶ä»–SKUé”€å”®é‡(#)'
        if c_halo in df_term.columns:
            df_term[c_halo] = pd.to_numeric(df_term[c_halo], errors='coerce').fillna(0)
            halo = df_term[df_term[c_halo]>0].sort_values(by=c_halo, ascending=False).head(20)
            if not halo.empty: st.dataframe(halo[['å®¢æˆ·æœç´¢è¯', c_halo, 'èŠ±è´¹']], use_container_width=True)