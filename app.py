import streamlit as st
import pandas as pd
import requests
import json
import os
from datetime import datetime

# === 1. å…¨å±€é…ç½® ===
st.set_page_config(
    page_title="Amazon AI æŒ‡æŒ¥å®˜ (v5.3 æ™ºèƒ½ç‰ˆ)", 
    layout="wide", 
    page_icon="ğŸ§¬",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .main { background-color: #f8f9fa; }
    div[data-testid="stMetric"] { background-color: white; border: 1px solid #ddd; padding: 10px; border-radius: 8px; }
    .stTabs [data-baseweb="tab-list"] { gap: 8px; }
    .stButton>button { width: 100%; border-radius: 4px; }
    .stAlert { padding: 10px; }
</style>
""", unsafe_allow_html=True)

# === 2. æ ¸å¿ƒé€»è¾‘ ===
DATA_FILE = "deepseek_cot_data.jsonl"

def generate_and_save_ai_thought(api_key, term, spend, clicks, orders, user_intent):
    if not api_key:
        st.error("âŒ éœ€è¦ API Key")
        return None
    prompt = f"æˆ‘æ˜¯äºšé©¬é€Šè¿è¥ã€‚äº§å“Makeup Mirrorã€‚åˆ†æè¯'{term}'ï¼ŒèŠ±è´¹${spend}ï¼Œç‚¹å‡»{clicks}ï¼Œè®¢å•{orders}ã€‚è¾“å‡ºJSONï¼šreasoning, actionã€‚å€¾å‘ï¼š{user_intent}ã€‚"
    try:
        with st.spinner(f"ğŸ§  AI åˆ†æä¸­..."):
            res = requests.post(
                "https://api.deepseek.com/chat/completions",
                headers={"Authorization": f"Bearer {api_key}"},
                json={"model": "deepseek-chat", "messages": [{"role": "user", "content": prompt}], "temperature": 0.7, "response_format": {"type": "json_object"}}
            )
            if res.status_code == 200:
                ai_json = json.loads(res.json()['choices'][0]['message']['content'])
                data = {"messages": [{"role": "system", "content": "PPCä¸“å®¶"}, {"role": "user", "content": f"è¯:{term},è´¹:{spend}"}, {"role": "assistant", "content": f"é€»è¾‘:{ai_json.get('reasoning')}\nå»ºè®®:{ai_json.get('action')}"}]}
                with open(DATA_FILE, "a", encoding="utf-8") as f: f.write(json.dumps(data, ensure_ascii=False) + "\n")
                st.toast("âœ… å·²ä¿å­˜")
                return ai_json.get('reasoning')
    except Exception as e: st.error(f"Error: {e}")

# === 3. ä¾§è¾¹æ  ===
st.sidebar.title("ğŸ§¬ æ§åˆ¶å° v5.3")
default_key = "sk-55cc3f56742f4e43be099c9489e02911"
deepseek_key = st.sidebar.text_input("ğŸ”‘ DeepSeek Key", value=default_key, type="password")
product_name = st.sidebar.text_input("ğŸ“¦ äº§å“åç§°", value="Makeup Mirror")

if os.path.exists(DATA_FILE):
    with open(DATA_FILE, "r", encoding="utf-8") as f: count = sum(1 for _ in f)
    st.sidebar.metric("ğŸ“š å·²ç§¯ç´¯æ•™æ", f"{count} æ¡")
    with open(DATA_FILE, "r", encoding="utf-8") as f: st.sidebar.download_button("ğŸ“¥ ä¸‹è½½æ•°æ®", f, file_name="finetune.jsonl")

# === 4. ä¸»ç•Œé¢ ===
st.title("ğŸ§¬ Amazon AI æŒ‡æŒ¥å®˜ (v5.3 æ™ºèƒ½è¯»å–ç‰ˆ)")
st.caption("ğŸš€ ä¿®å¤ Bulk è¡¨å¤´è¯†åˆ«é—®é¢˜ | è‡ªåŠ¨é”å®šæ•°æ®è¡Œ")

c1, c2 = st.columns(2)
with c1:
    file_bulk = st.file_uploader("ğŸ“‚ 1. ä¸Šä¼  Bulk è¡¨æ ¼ (æ”¯æŒå¸¦æ‚ä¹±è¡¨å¤´)", type=['xlsx', 'csv'], key="bulk")
with c2:
    file_term = st.file_uploader("ğŸ“‚ 2. ä¸Šä¼  Search Term (å·²éªŒè¯æˆåŠŸ)", type=['xlsx', 'csv'], key="term")

# ğŸ”¥ğŸ”¥ğŸ”¥ æ ¸å¿ƒå‡çº§ï¼šæ™ºèƒ½è¯»å–å‡½æ•° ğŸ”¥ğŸ”¥ğŸ”¥
def smart_load_bulk(file):
    if not file: return pd.DataFrame()
    try:
        # 1. å¦‚æœæ˜¯ CSVï¼Œé€šå¸¸æ¯”è¾ƒè§„èŒƒï¼Œç›´æ¥è¯»
        if file.name.endswith('.csv'):
            return pd.read_csv(file)
        
        # 2. å¦‚æœæ˜¯ Excelï¼Œå¾ˆå¯èƒ½æœ‰ metadata å¹²æ‰°
        # å…ˆç›²è¯»å‰ 20 è¡Œï¼Œä¸è®¾è¡¨å¤´
        df_preview = pd.read_excel(file, header=None, nrows=20, engine='openpyxl')
        
        # å¯»æ‰¾çœŸæ­£çš„è¡¨å¤´è¡Œ (åŒ…å« 'Record Type' æˆ– 'Entity' çš„é‚£ä¸€è¡Œ)
        header_row_idx = None
        for i, row in df_preview.iterrows():
            row_str = row.astype(str).str.lower().tolist()
            # åªè¦è¿™ä¸€è¡Œé‡Œæœ‰ record type æˆ–è€… entityï¼Œå°±è®¤å®šå®ƒæ˜¯è¡¨å¤´
            if any('record type' in s or 'entity' in s or 'å®ä½“å±‚çº§' in s for s in row_str):
                header_row_idx = i
                break
        
        # å¦‚æœæ‰¾åˆ°äº†ï¼Œå°±ä»é‚£ä¸€è¡Œé‡æ–°è¯»
        if header_row_idx is not None:
            st.toast(f"âœ… æ™ºèƒ½å®šä½ï¼šåœ¨ç¬¬ {header_row_idx+1} è¡Œå‘ç°è¡¨å¤´ï¼Œæ­£åœ¨è§£æ...")
            file.seek(0) # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
            return pd.read_excel(file, header=header_row_idx, engine='openpyxl')
        else:
            # æ²¡æ‰¾åˆ°ï¼Œå°±ç¡¬è¯»ç¬¬ä¸€è¡Œ
            file.seek(0)
            return pd.read_excel(file, engine='openpyxl')

    except Exception as e:
        st.error(f"æ™ºèƒ½è¯»å–å¤±è´¥: {e}")
        return pd.DataFrame()

# ä½¿ç”¨æ–°å‡½æ•°è¯»å–
df_bulk = smart_load_bulk(file_bulk)

# Search Term ä¹‹å‰è¯»æˆåŠŸäº†ï¼Œä¿æŒç®€å•è¯»å–
def load_simple(file):
    if not file: return pd.DataFrame()
    try:
        if file.name.endswith('.csv'): return pd.read_csv(file)
        return pd.read_excel(file, engine='openpyxl')
    except: return pd.DataFrame()

df_term = load_simple(file_term)

# æ¸…æ´—åˆ—å
if not df_bulk.empty: df_bulk.columns = df_bulk.columns.astype(str).str.strip()
if not df_term.empty: df_term.columns = df_term.columns.astype(str).str.strip()

# === è§£æ Bulk åˆ— ===
bk_cols = {}
if not df_bulk.empty:
    # æ¨¡ç³ŠåŒ¹é…ï¼Œå¢åŠ å®¹é”™ç‡
    cols = df_bulk.columns
    bk_cols = {
        'entity': next((c for c in cols if c in ["å®ä½“å±‚çº§", "Record Type", "Entity"]), None),
        'kw': next((c for c in cols if c in ["å…³é”®è¯æ–‡æœ¬", "Keyword Text", "Keyword", "Targeting", "Targeting Expression"]), None),
        'bid': next((c for c in cols if c in ["ç«ä»·", "Keyword Bid", "Bid"]), None),
        'spend': next((c for c in cols if c in ["èŠ±è´¹", "Spend"]), None),
        'sales': next((c for c in cols if c in ["é”€é‡", "Sales"]), None),
        'orders': next((c for c in cols if c in ["è®¢å•æ•°é‡", "Orders"]), None),
        'clicks': next((c for c in cols if c in ["ç‚¹å‡»é‡", "Clicks"]), None),
    }

    if bk_cols['entity'] and bk_cols['kw']:
        try:
            # ç­›é€‰å…³é”®è¯è¡Œ
            df_kws = df_bulk[df_bulk[bk_cols['entity']].astype(str).str.contains('Keyword|å…³é”®è¯|Targeting', case=False, na=False)].copy()
            for c in [bk_cols['spend'], bk_cols['sales'], bk_cols['orders'], bk_cols['clicks'], bk_cols['bid']]:
                if c: df_kws[c] = pd.to_numeric(df_kws[c], errors='coerce').fillna(0)
            if bk_cols['spend'] and bk_cols['sales']:
                df_kws['ACoS'] = df_kws.apply(lambda x: x[bk_cols['spend']]/x[bk_cols['sales']] if x[bk_cols['sales']]>0 else 0, axis=1)
        except: pass

# === 5. åŠŸèƒ½åŒº ===
tab1, tab2, tab3 = st.tabs(["ğŸ§  AI è‡ªåŠ¨æ ‡æ³¨", "ğŸ“ˆ çœ‹æ¿", "ğŸ’° ç«ä»·"])

with tab1:
    st.subheader("ğŸ§  è®­ç»ƒæ•°æ®ç§¯ç´¯")
    if not df_term.empty:
        st_term_col = next((c for c in df_term.columns if c in ["å®¢æˆ·æœç´¢è¯", "Search Term", "Customer Search Term"]), None)
        st_spend_col = next((c for c in df_term.columns if c in ["èŠ±è´¹", "Spend"]), None)
        
        if st_term_col and st_spend_col:
            st.success(f"âœ… Search Term æ•°æ®å°±ç»ª: {len(df_term)} è¡Œ")
            df_term[st_spend_col] = pd.to_numeric(df_term[st_spend_col], errors='coerce').fillna(0)
            
            # ç­›é€‰é«˜èŠ±è´¹0è½¬åŒ–
            st_orders_col = next((c for c in df_term.columns if c in ["è®¢å•æ•°é‡", "Orders", "7 Day Total Orders"]), None)
            if st_orders_col:
                df_term[st_orders_col] = pd.to_numeric(df_term[st_orders_col], errors='coerce').fillna(0)
                mask = (df_term[st_orders_col] == 0) & (df_term[st_spend_col] > 0)
                review_df = df_term[mask].sort_values(by=st_spend_col, ascending=False).head(10)
                
                st.write("ğŸ‘‡ é‡ç‚¹å®¡æŸ¥ä»¥ä¸‹â€œæµªè´¹é’±â€çš„è¯ï¼š")
                for idx, row in review_df.iterrows():
                    with st.expander(f"{row[st_term_col]} (Cost: ${row[st_spend_col]:.2f})"):
                        c1, c2 = st.columns(2)
                        with c1: 
                            if st.button("âŒ å¦å®š (AIç”Ÿæˆç†ç”±)", key=f"ai_neg_{idx}"):
                                generate_and_save_ai_thought(deepseek_key, row[st_term_col], row[st_spend_col], 0, 0, "Negative")
                        with c2:
                             if st.button("ğŸ‘€ è§‚å¯Ÿ (AIç”Ÿæˆç†ç”±)", key=f"ai_kp_{idx}"):
                                generate_and_save_ai_thought(deepseek_key, row[st_term_col], row[st_spend_col], 0, 0, "Keep")
            else:
                st.warning("Search Term è¡¨æ ¼ç¼ºè®¢å•åˆ—")
        else:
            st.warning("Search Term è¡¨æ ¼ç¼ºå…³é”®åˆ—")
    else:
        st.info("è¯·ä¸Šä¼  Search Term è¡¨æ ¼")

with tab2:
    st.subheader("ğŸ“ˆ è´¦æˆ·é€è§†")
    if not df_bulk.empty:
        if 'df_kws' in locals() and not df_kws.empty:
            # æˆåŠŸå±•ç¤º
            st.success(f"âœ… æˆåŠŸè§£æ Bulk æ•°æ®ï¼šå…± {len(df_kws)} ä¸ªå…³é”®è¯")
            
            # 1. æ ¸å¿ƒæŒ‡æ ‡
            t_spend = df_kws[bk_cols['spend']].sum()
            t_sales = df_kws[bk_cols['sales']].sum()
            t_acos = t_spend / t_sales if t_sales > 0 else 0
            
            m1, m2, m3 = st.columns(3)
            m1.metric("æ€»èŠ±è´¹", f"${t_spend:,.2f}")
            m2.metric("æ€»é”€å”®é¢", f"${t_sales:,.2f}")
            m3.metric("ç»¼åˆ ACoS", f"{t_acos:.2%}")
            
            # 2. æ°”æ³¡å›¾
            st.markdown("#### ğŸ” å…³é”®è¯åˆ†å¸ƒå›¾ (Spend vs Sales)")
            chart_data = df_kws[df_kws[bk_cols['spend']] > 0]
            if not chart_data.empty:
                st.scatter_chart(chart_data, x=bk_cols['spend'], y=bk_cols['sales'], size=bk_cols['clicks'], color='ACoS')
            else:
                st.info("æ•°æ®ä¸­æ²¡æœ‰èŠ±è´¹å¤§äº0çš„è¯ã€‚")
        else:
            st.error("âŒ ä¾ç„¶æ‰¾ä¸åˆ°å…³é”®è¯åˆ—ã€‚")
            st.write("è¯Šæ–­ä¿¡æ¯ï¼šä»¥ä¸‹æ˜¯æˆ‘ä»¬æ‰¾åˆ°çš„åˆ—åï¼Œè¯·æ£€æŸ¥æ˜¯å¦åŒ…å« 'Keyword Text' æˆ– 'Targeting'ï¼š")
            st.code(list(df_bulk.columns))
            st.dataframe(df_bulk.head(3))
    else:
        st.info("è¯·ä¸Šä¼  Bulk è¡¨æ ¼")

with tab3:
    st.subheader("ğŸ’° ç«ä»·ä¼˜åŒ–")
    if 'df_kws' in locals() and not df_kws.empty:
        bad = df_kws[(df_kws[bk_cols['orders']]>0) & (df_kws['ACoS']>0.3)].sort_values(by='ACoS', ascending=False).head(20)
        if not bad.empty:
            st.dataframe(bad[[bk_cols['kw'], bk_cols['bid'], 'ACoS', bk_cols['spend']]], use_container_width=True)
        else:
            st.success("ç«ä»·æ§åˆ¶å®Œç¾ï¼Œæ— é«˜ACoSè¯ã€‚")
    else:
        st.info("ç­‰å¾… Bulk æ•°æ®...")