import streamlit as st
import pandas as pd
import io
import requests
import json

# === ç½‘é¡µé…ç½® ===
st.set_page_config(page_title="äºšé©¬é€Šå¹¿å‘Šå…¨èƒ½ç‹ (ç²¾å‡†å®šä½ç‰ˆ)", layout="wide", page_icon="ğŸ¯")
st.title("ğŸ¯ Amazon å¹¿å‘Šä¼˜åŒ–å…¨èƒ½ç‹ (å¸¦å¹¿å‘Šç»„/åŒ¹é…ç±»å‹)")
st.info("ğŸ’¡ å·²å‡çº§ï¼šæ–°å¢ã€å¹¿å‘Šç»„ã€‘å’Œã€åŒ¹é…ç±»å‹ã€‘åˆ—ï¼Œç²¾å‡†å®šä½æ¯ä¸€ä¸ªæŠ•æ”¾ï¼")

# === ä¾§è¾¹æ è®¾ç½® ===
st.sidebar.header("ğŸ”‘ AI è®¾ç½®")
deepseek_key = st.sidebar.text_input("DeepSeek API Key", type="password")
product_name = st.sidebar.text_input("äº§å“åç§°", value="LED Makeup Mirror")

st.sidebar.header("âš™ï¸ ç«ä»·è§„åˆ™")
target_acos = st.sidebar.slider("ğŸ¯ ç›®æ ‡ ACoS", 10, 60, 30) / 100

st.sidebar.header("ğŸ›¡ï¸ å¦è¯è§„åˆ™")
neg_clicks = st.sidebar.number_input("ğŸš« å¦è¯é˜ˆå€¼ (ç‚¹å‡»æ•°)", value=10, step=1)

# === ä¸Šä¼ åŒºåŸŸ ===
st.write("---")
c1, c2 = st.columns(2)
with c1:
    file_bulk = st.file_uploader("ğŸ“‚ 1. æ‹–å…¥ã€æ‰¹é‡æ“ä½œè¡¨æ ¼ã€‘(Bulk)", type=['xlsx'], key="bulk")
with c2:
    file_term = st.file_uploader("ğŸ“‚ 2. æ‹–å…¥ã€æœç´¢è¯æŠ¥å‘Šã€‘(Search Term)", type=['xlsx'], key="term")
st.write("---")

# === DeepSeek å‡½æ•° ===
def call_deepseek_analysis(api_key, product, neg_data, bid_data):
    url = "https://api.deepseek.com/chat/completions"
    prompt = f"""
    æˆ‘æ˜¯äºšé©¬é€Šå–å®¶ï¼Œäº§å“æ˜¯ã€{product}ã€‘ã€‚è¯·åˆ†ææ•°æ®å¹¶ç»™å‡ºå»ºè®®ï¼š
    
    1. ã€å¾…å¦å®šæœç´¢è¯ (ç‚¹å‡»å¤šä½†0å•)ã€‘ï¼š
    {neg_data.to_string(index=False)}
    * ç»“åˆåŒ¹é…ç±»å‹(Match Type)å’Œå¹¿å‘Šç»„ï¼Œåˆ†æè¿™äº›è¯ä¸ºä»€ä¹ˆè·‘åï¼Ÿ
    * å“ªäº›è¯å»ºè®®ç²¾å‡†å¦å®šï¼Ÿ

    2. ã€éœ€é™ä»·æŠ•æ”¾ (ACoSé«˜)ã€‘ï¼š
    {bid_data.to_string(index=False)}
    * ç®€è¿°ä¼˜åŒ–å»ºè®®ã€‚
    
    è¯·ç”¨ Markdown æ ¼å¼ï¼Œç®€ç»ƒç›´æ¥ã€‚
    """
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    data = {
        "model": "deepseek-chat",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.5
    }
    try:
        res = requests.post(url, headers=headers, json=data)
        if res.status_code == 200: return res.json()['choices'][0]['message']['content']
        return f"AI æŠ¥é”™: {res.text}"
    except Exception as e: return f"é”™è¯¯: {e}"

# === 1ï¸âƒ£ ç«ä»·ä¼˜åŒ– (Bulk) ===
if file_bulk:
    try:
        dfs = pd.read_excel(file_bulk, sheet_name=None, engine='openpyxl')
        bulk_df = pd.DataFrame()
        found_sheet_name = ""

        # ç²¾å‡†æ‰¾è¡¨
        for name, df in dfs.items():
            df.columns = df.columns.astype(str).str.strip()
            cols = df.columns.tolist()
            if ('å®ä½“å±‚çº§' in cols or 'Record Type' in cols) and \
               ('å…³é”®è¯æ–‡æœ¬' in cols or 'Keyword Text' in cols):
                bulk_df = df
                found_sheet_name = name
                break
        
        if bulk_df.empty:
            st.error("âŒ æ²¡æ‰¾åˆ°æ•°æ®è¡¨ï¼è¯·æ£€æŸ¥æ–‡ä»¶ã€‚")
        else:
            st.success(f"âœ… ç«ä»·æ•°æ®æ¥æº: ã€{found_sheet_name}ã€‘")

            # === è¯¦ç»†åˆ—åæ˜ å°„ (å«å¹¿å‘Šç»„å’ŒåŒ¹é…ç±»å‹) ===
            col_map = {
                'å®ä½“å±‚çº§': 'Record Type', 'Record Type': 'Record Type',
                'å¹¿å‘Šæ´»åŠ¨åç§°ï¼ˆä»…ä¾›å‚è€ƒï¼‰': 'Campaign', 'å¹¿å‘Šæ´»åŠ¨åç§°': 'Campaign',
                'å¹¿å‘Šç»„åç§°ï¼ˆä»…ä¾›å‚è€ƒï¼‰': 'Ad Group', 'å¹¿å‘Šç»„åç§°': 'Ad Group', # æ–°å¢
                'åŒ¹é…ç±»å‹': 'Match Type', 'Match Type': 'Match Type', # æ–°å¢
                'å…³é”®è¯æ–‡æœ¬': 'Keyword', 'Keyword Text': 'Keyword',
                'ç«ä»·': 'Max Bid', 'Max Bid': 'Max Bid',
                'èŠ±è´¹': 'Spend', 'Spend': 'Spend',
                'é”€é‡': 'Sales', 'Sales': 'Sales',
                'è®¢å•æ•°é‡': 'Orders', 'Orders': 'Orders',
                'å±•ç¤ºé‡': 'Impressions', 'Impressions': 'Impressions',
                'ç‚¹å‡»é‡': 'Clicks', 'Clicks': 'Clicks',
                'ç‚¹å‡»ç‡': 'CTR', 'Click-through Rate': 'CTR',
                'è½¬åŒ–ç‡': 'CVR', 'Conversion Rate': 'CVR',
                'æ‹“å±•å•†å“æŠ•æ”¾ç¼–å·': 'Targeting', 'å•†å“æŠ•æ”¾ ID': 'Targeting ID'
            }
            df_clean = bulk_df.rename(columns=col_map)
            df_clean = df_clean.loc[:, ~df_clean.columns.duplicated()]

            # ç­›é€‰
            df_clean['Record Type'] = df_clean['Record Type'].astype(str)
            mask = df_clean['Record Type'].str.contains('å…³é”®è¯|Keyword|å•†å“å®šå‘|Product Targeting', case=False, na=False)
            data_bid = df_clean[mask].copy()

            # æ•´ç†æŠ•æ”¾ç›®æ ‡åˆ—
            if 'Keyword' not in data_bid.columns: data_bid['Keyword'] = None
            data_bid['Target'] = data_bid['Keyword']
            if 'Targeting' in data_bid.columns: 
                data_bid['Target'] = data_bid['Target'].fillna(data_bid['Targeting'])
            
            # è½¬æ•°å­—
            num_cols = ['Spend', 'Sales', 'Orders', 'Max Bid', 'Impressions', 'Clicks', 'CTR', 'CVR']
            for c in num_cols:
                if c in data_bid.columns: data_bid[c] = pd.to_numeric(data_bid[c], errors='coerce').fillna(0)
            
            data_bid['ACoS'] = data_bid['Spend'] / data_bid['Sales']
            data_bid['ACoS'] = data_bid['ACoS'].fillna(0)

            # æ‰¾å‡ºéœ€è¦ä¼˜åŒ–çš„è¡Œ
            bad_bids = data_bid[(data_bid['Orders'] > 0) & (data_bid['ACoS'] > target_acos)].copy()
            bad_bids['å»ºè®®æ–°ç«ä»·'] = bad_bids['Max Bid'] * 0.85

            st.subheader("1ï¸âƒ£ ç«ä»·ä¼˜åŒ–å»ºè®® (ç²¾ç¡®åˆ°å¹¿å‘Šç»„)")
            if not bad_bids.empty:
                # === å…³é”®ï¼šè°ƒæ•´åˆ—é¡ºåºï¼ŒæŠŠå¹¿å‘Šç»„å’ŒåŒ¹é…ç±»å‹æ”¾åœ¨å‰é¢ ===
                show_cols = ['Campaign', 'Ad Group', 'Target', 'Match Type', 'Max Bid', 'å»ºè®®æ–°ç«ä»·', 'Orders', 'ACoS', 'Spend', 'Sales', 'CVR']
                final_cols = [c for c in show_cols if c in bad_bids.columns]
                
                st.dataframe(
                    bad_bids[final_cols].style.format({
                        'ACoS': '{:.2%}', 'CVR': '{:.2%}',
                        'Spend': '{:.2f}', 'Sales': '{:.2f}',
                        'Max Bid': '{:.2f}', 'å»ºè®®æ–°ç«ä»·': '{:.2f}'
                    }),
                    use_container_width=True
                )
            else:
                st.success("âœ… ç«ä»·è¡¨ç°è‰¯å¥½ã€‚")

    except Exception as e:
        st.error(f"Bulk æ–‡ä»¶é”™è¯¯: {e}")

# === 2ï¸âƒ£ å¦è¯ä¼˜åŒ– (Search Term) ===
neg_ai_data = pd.DataFrame()
if file_term:
    try:
        term_df = pd.read_excel(file_term, engine='openpyxl')
        term_df.columns = term_df.columns.astype(str).str.strip()

        # === è¯¦ç»†åˆ—åæ˜ å°„ ===
        st_col_map = {
            'å®¢æˆ·æœç´¢è¯': 'Search Term', 'Customer Search Term': 'Search Term',
            'å¹¿å‘Šæ´»åŠ¨åç§°': 'Campaign', 'Campaign Name': 'Campaign',
            'å¹¿å‘Šç»„åç§°': 'Ad Group', 'Ad Group Name': 'Ad Group', # æ–°å¢
            'åŒ¹é…ç±»å‹': 'Match Type', 'Match Type': 'Match Type', # æ–°å¢
            'æŠ•æ”¾': 'Targeting', 'Targeting': 'Targeting',
            'èŠ±è´¹': 'Spend', 'Spend': 'Spend',
            'ç‚¹å‡»é‡': 'Clicks', 'Clicks': 'Clicks',
            '7å¤©æ€»è®¢å•æ•°(#)': 'Orders', '7å¤©æ€»è®¢å•æ•°': 'Orders', 'è®¢å•æ•°é‡': 'Orders',
            'æ¯æ¬¡ç‚¹å‡»æˆæœ¬(CPC)': 'CPC',
            'å¹¿å‘ŠæŠ•å…¥äº§å‡ºæ¯” (ACOS) æ€»è®¡': 'ACoS'
        }
        term_df = term_df.rename(columns=st_col_map)
        term_df = term_df.loc[:, ~term_df.columns.duplicated()]
        
        for c in ['Spend', 'Orders', 'Clicks', 'CPC', 'ACoS']:
             if c in term_df.columns: term_df[c] = pd.to_numeric(term_df[c], errors='coerce').fillna(0)

        if 'Orders' in term_df.columns and 'Clicks' in term_df.columns:
            neg_candidates = term_df[(term_df['Clicks'] >= neg_clicks) & (term_df['Orders'] == 0)].copy()
            neg_candidates = neg_candidates.sort_values(by='Spend', ascending=False)
            neg_ai_data = neg_candidates.head(10)

            st.subheader("2ï¸âƒ£ å¦è¯å»ºè®® (ç²¾ç¡®åˆ°å¹¿å‘Šç»„)")
            if not neg_candidates.empty:
                st.error(f"ğŸš¨ å‘ç° {len(neg_candidates)} ä¸ªæ— æ•ˆæœç´¢è¯ï¼")
                
                # === å…³é”®ï¼šå±•ç¤ºåˆ—åŒ…å«å¹¿å‘Šç»„å’ŒåŒ¹é…ç±»å‹ ===
                st_show_cols = ['Campaign', 'Ad Group', 'Search Term', 'Match Type', 'Clicks', 'Spend', 'CPC', 'Targeting']
                st_final_cols = [c for c in st_show_cols if c in neg_candidates.columns]

                st.dataframe(
                    neg_candidates[st_final_cols].head(50).style.format({
                        'Spend': '{:.2f}', 'CPC': '{:.2f}'
                    }),
                    use_container_width=True
                )
                
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    neg_candidates.to_excel(writer, index=False)
                st.download_button("ğŸ“¥ ä¸‹è½½è¯¦ç»†å¦è¯è¡¨", output, "Negative_Keywords_Detailed.xlsx")
            else:
                st.success("âœ… æœç´¢è¯å¾ˆå¹²å‡€ã€‚")
        else:
            st.error(f"âŒ ç¼ºå°‘å¿…è¦åˆ—ï¼æ£€æµ‹åˆ°çš„åˆ—åï¼š{list(term_df.columns)}")

    except Exception as e:
        st.error(f"æœç´¢è¯æŠ¥å‘Šé”™è¯¯: {e}")

# === 3. AI åˆ†æ ===
if file_bulk and file_term:
    st.write("---")
    st.subheader("ğŸ¤– DeepSeek ç»¼åˆè¯Šæ–­")
    if st.button("å¼€å§‹ AI åˆ†æ"):
        if not deepseek_key:
            st.error("è¯·åœ¨å·¦ä¾§å¡«å…¥ Key")
        else:
            ai_bid_data = pd.DataFrame()
            if 'bad_bids' in locals() and not bad_bids.empty:
                ai_bid_data = bad_bids[['Ad Group', 'Target', 'Match Type', 'ACoS', 'Spend']].head(5)
            
            with st.spinner("AI æ­£åœ¨åˆ†æå¹¿å‘Šç»„ç»“æ„..."):
                report = call_deepseek_analysis(deepseek_key, product_name, neg_ai_data, ai_bid_data)
                st.markdown(report)
