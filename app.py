import streamlit as st
import pandas as pd
import requests
import json
import os
from datetime import datetime

# === 1. å…¨å±€é…ç½® ===
st.set_page_config(
    page_title="Amazon AI æŒ‡æŒ¥å®˜ (v5.9 æ·±åº¦ç‰ˆ)", 
    layout="wide", 
    page_icon="ğŸ§ ",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .main { background-color: #f8f9fa; }
    div[data-testid="stMetric"] { background-color: white; border: 1px solid #ddd; padding: 10px; border-radius: 8px; }
    .stTabs [data-baseweb="tab-list"] { gap: 8px; }
    .stButton>button { width: 100%; border-radius: 4px; }
    .ai-thought { background-color: #e8f0fe; padding: 15px; border-radius: 8px; border-left: 5px solid #1a73e8; margin-top: 10px; font-size: 14px; }
</style>
""", unsafe_allow_html=True)

# === 2. æ ¸å¿ƒï¼šAI æ·±åº¦æ€è€ƒç”Ÿæˆå™¨ (Prompt å‡çº§) ===
DATA_FILE = "deepseek_cot_data.jsonl"

def generate_and_save_ai_thought(api_key, term, spend, clicks, orders, user_intent):
    if not api_key:
        st.error("âŒ éœ€è¦ API Key")
        return None
    
    # ğŸ”¥ğŸ”¥ğŸ”¥ æ ¸å¿ƒå‡çº§ï¼šè¶…çº§è¯¦ç»†çš„ Prompt ğŸ”¥ğŸ”¥ğŸ”¥
    prompt = f"""
    ã€è§’è‰²è®¾å®šã€‘
    ä½ æ˜¯ä¸€åæ‹¥æœ‰ 10 å¹´ç»éªŒçš„äºšé©¬é€Š PPC å¹¿å‘Šä¸“å®¶ã€‚ä½ çš„äº§å“æ˜¯ "Makeup Mirror" (åŒ–å¦†é•œ)ã€‚
    
    ã€ä»»åŠ¡ç›®æ ‡ã€‘
    è¯·åˆ†ææœç´¢è¯ï¼š"{term}"ã€‚
    å½“å‰æ•°æ®è¡¨ç°ï¼šèŠ±è´¹ ${spend}, ç‚¹å‡» {clicks}, è®¢å• {orders}ã€‚
    
    ã€åˆ†ææ¡†æ¶ (å¿…é¡»ä¸¥æ ¼æ‰§è¡Œ)ã€‘
    è¯·ä¸è¦åªçœ‹æ•°æ®ï¼Œå¿…é¡»ç»“åˆè¯­ä¹‰è¿›è¡Œæ·±åº¦æ¨ç†ã€‚è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ€è€ƒï¼š
    1. **ç”¨æˆ·æ„å›¾ (User Intent)**: æœç´¢è¿™ä¸ªè¯çš„ç”¨æˆ·ï¼Œä»–å¿ƒé‡Œæƒ³è¦ä¹°ä»€ä¹ˆï¼Ÿæ˜¯æƒ³ä¹°é•œå­ï¼Œè¿˜æ˜¯é…ä»¶ï¼Œè¿˜æ˜¯å®Œå…¨ä¸ç›¸å…³çš„ä¸œè¥¿ï¼Ÿ
    2. **ç›¸å…³æ€§ (Relevance)**: è¿™ä¸ªè¯ä¸æˆ‘çš„äº§å“ï¼ˆåŒ–å¦†é•œï¼‰åŒ¹é…åº¦å¦‚ä½•ï¼Ÿæ˜¯ç²¾å‡†ã€å®½æ³›ã€è¿˜æ˜¯äº’è¡¥ï¼Ÿ
    3. **æ•°æ®è¯Šæ–­ (Data Check)**: å½“å‰çš„èŠ±è´¹å’Œç‚¹å‡»é‡æ˜¯å¦å·²ç»è¾¾åˆ°â€œç»Ÿè®¡å­¦æ˜¾è‘—â€ï¼ŸCPC æ˜¯å¦è¿‡é«˜ï¼Ÿ
    4. **å†³ç­–é€»è¾‘ (Verdict)**: ç»¼åˆä»¥ä¸Šä¸‰ç‚¹ï¼Œä¸ºä»€ä¹ˆä½ å»ºè®®æ‰§è¡Œè¯¥æ“ä½œï¼Ÿ
    
    ã€è¾“å‡ºè¦æ±‚ã€‘
    è¯·è¾“å‡º JSON æ ¼å¼ï¼š
    - "reasoning": ä¸€æ®µ 100-200 å­—çš„è¯¦ç»†åˆ†æï¼Œè¯­æ°”è¦ä¸“ä¸šã€çŠ€åˆ©ã€‚
    - "action": å»ºè®®æ“ä½œ (Negative Exact / Negative Phrase / Keep / Increase Bid)ã€‚
    
    æˆ‘çš„é¢„åˆ¤æ˜¯ï¼š{user_intent} (ä»…ä¾›å‚è€ƒï¼Œè¯·ä»¥ä½ çš„ä¸“å®¶è§†è§’ä¸ºå‡†)ã€‚
    """

    try:
        with st.spinner(f"ğŸ§  AI æ­£åœ¨æ·±åº¦å‰–æ '{term}' (è¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿ)..."):
            res = requests.post(
                "https://api.deepseek.com/chat/completions",
                headers={"Authorization": f"Bearer {api_key}"},
                json={
                    "model": "deepseek-chat",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.8, # ç¨å¾®æé«˜åˆ›é€ åŠ›ï¼Œè®©åˆ†ææ›´ä¸°å¯Œ
                    "response_format": {"type": "json_object"} 
                }
            )
            if res.status_code == 200:
                content = res.json()['choices'][0]['message']['content']
                ai_json = json.loads(content)
                
                # ä¿å­˜é«˜è´¨é‡è®­ç»ƒæ•°æ®
                train_data = {
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç²¾é€š Amazon PPC çš„ä¸“å®¶ï¼Œæ“…é•¿é€šè¿‡ç”¨æˆ·æ„å›¾å’Œæ•°æ®è¿›è¡Œæ·±åº¦å½’å› åˆ†æã€‚"},
                        {"role": "user", "content": f"è¯·åˆ†ææœç´¢è¯: {term}\næ•°æ®: èŠ±è´¹ ${spend}, ç‚¹å‡» {clicks}, è®¢å• {orders}"},
                        {"role": "assistant", "content": f"ã€æ·±åº¦åˆ†æã€‘\n{ai_json.get('reasoning')}\n\nã€å»ºè®®æ“ä½œã€‘\n{ai_json.get('action')}"}
                    ]
                }
                with open(DATA_FILE, "a", encoding="utf-8") as f:
                    f.write(json.dumps(train_data, ensure_ascii=False) + "\n")
                
                return ai_json.get('reasoning')
            else:
                st.error(f"API æŠ¥é”™: {res.text}")
    except Exception as e:
        st.error(f"ç½‘ç»œé”™è¯¯: {e}")

# === 3. ä¾§è¾¹æ  ===
st.sidebar.title("ğŸ§  æ§åˆ¶å° v5.9")
default_key = "sk-55cc3f56742f4e43be099c9489e02911"
deepseek_key = st.sidebar.text_input("ğŸ”‘ DeepSeek Key", value=default_key, type="password")
product_name = st.sidebar.text_input("ğŸ“¦ äº§å“åç§°", value="Makeup Mirror")

st.sidebar.markdown("---")
# é˜ˆå€¼æ§åˆ¶
with st.sidebar.expander("âš™ï¸ è§„åˆ™è®¾ç½®", expanded=True):
    target_acos = st.slider("ç›®æ ‡ ACoS", 0.1, 1.0, 0.3)
    gold_acos = st.slider("é»„é‡‘è¯ ACoS ä¸Šé™", 0.1, 1.0, 0.2)

if os.path.exists(DATA_FILE):
    with open(DATA_FILE, "r", encoding="utf-8") as f: count = sum(1 for _ in f)
    st.sidebar.metric("ğŸ“š å·²ç§¯ç´¯æ·±åº¦æ•™æ", f"{count} æ¡")
    with open(DATA_FILE, "r", encoding="utf-8") as f: st.sidebar.download_button("ğŸ“¥ ä¸‹è½½è®­ç»ƒæ•°æ®", f, file_name="finetune_deep.jsonl")

# === 4. ä¸»ç•Œé¢ ===
st.title("ğŸ§  Amazon AI æŒ‡æŒ¥å®˜ (v5.9 æ·±åº¦æ€è€ƒç‰ˆ)")
st.caption("ğŸš€ å‡çº§ Promptï¼šå¼ºåˆ¶ AI è¿›è¡Œã€æ„å›¾åˆ†æ + è¯­ä¹‰åŒ¹é… + æ•°æ®è¯Šæ–­ã€‘çš„ä¸‰ç»´åˆ†æ")

c1, c2 = st.columns(2)
with c1:
    file_bulk = st.file_uploader("ğŸ“‚ 1. ä¸Šä¼  Bulk è¡¨æ ¼", type=['xlsx', 'csv'], key="bulk")
with c2:
    file_term = st.file_uploader("ğŸ“‚ 2. ä¸Šä¼  Search Term è¡¨æ ¼", type=['xlsx', 'csv'], key="term")

# æ™ºèƒ½è¯»å– Bulk
def smart_load_bulk(file):
    if not file: return pd.DataFrame()
    try:
        if file.name.endswith('.csv'): return pd.read_csv(file)
        dfs = pd.read_excel(file, sheet_name=None, engine='openpyxl')
        for sheet_name, df in dfs.items():
            cols = df.columns.astype(str).tolist()
            has_record = any(x in cols for x in ['å®ä½“å±‚çº§', 'Record Type'])
            has_kw = any(x in cols for x in ['å…³é”®è¯æ–‡æœ¬', 'Keyword Text', 'æŠ•æ”¾', 'Targeting'])
            if has_record and has_kw:
                st.toast(f"âœ… å®šä½æ•°æ®è¡¨: {sheet_name}")
                return df
        return pd.DataFrame()
    except: return pd.DataFrame()

df_bulk = smart_load_bulk(file_bulk)

# Search Term è¯»å–
def load_simple(file):
    if not file: return pd.DataFrame()
    try:
        if file.name.endswith('.csv'): return pd.read_csv(file)
        return pd.read_excel(file, engine='openpyxl')
    except: return pd.DataFrame()

df_term = load_simple(file_term)

if not df_bulk.empty: df_bulk.columns = df_bulk.columns.astype(str).str.strip()
if not df_term.empty: df_term.columns = df_term.columns.astype(str).str.strip()

# å…¨å±€æ•°æ®é¢„å¤„ç†
bulk_ready = False
df_kws = pd.DataFrame()
bk_cols = {}

if not df_bulk.empty:
    cols = df_bulk.columns
    bk_cols['spend'] = 'èŠ±è´¹'
    bk_cols['sales'] = next((c for c in ['é”€é‡', 'é”€å”®é¢', '7å¤©æ€»é”€å”®é¢', 'Sales'] if c in cols), None)
    bk_cols['clicks'] = 'ç‚¹å‡»é‡'
    bk_cols['entity'] = 'å®ä½“å±‚çº§'
    bk_cols['kw'] = next((c for c in ['å…³é”®è¯æ–‡æœ¬', 'æŠ•æ”¾'] if c in cols), None)
    bk_cols['bid'] = next((c for c in ['ç«ä»·', 'Keyword Bid'] if c in cols), None)
    bk_cols['orders'] = 'è®¢å•æ•°é‡'

    if bk_cols['entity'] and bk_cols['kw'] and bk_cols['sales'] and bk_cols['spend']:
        df_kws = df_bulk[df_bulk[bk_cols['entity']].astype(str).str.contains('Keyword|å…³é”®è¯|Targeting', case=False, na=False)].copy()
        for c in [bk_cols['spend'], bk_cols['sales'], bk_cols['clicks'], bk_cols['bid'], bk_cols['orders']]:
            if c: df_kws[c] = pd.to_numeric(df_kws[c], errors='coerce').fillna(0)
        df_kws['ACoS'] = df_kws.apply(lambda x: x[bk_cols['spend']]/x[bk_cols['sales']] if x[bk_cols['sales']]>0 else 0, axis=1)
        bulk_ready = True

# === 5. åŠŸèƒ½æ ‡ç­¾é¡µ ===
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ§  AI æ·±åº¦è®­ç»ƒ", "ğŸ“ˆ æ•°æ®çœ‹æ¿", "ğŸ’° ç«ä»·ä¼˜åŒ–", "ğŸ† é»„é‡‘è¯", "ğŸ’« å…³è”åˆ†æ"
])

# --- Tab 1: AI è®­ç»ƒ (ç•Œé¢ä¼˜åŒ–) ---
with tab1:
    st.subheader("ğŸ§  AI è‡ªåŠ¨æ ‡æ³¨ (ç”Ÿæˆä¸“å®¶çº§æ•™æ)")
    st.info("ğŸ’¡ ç°åœ¨çš„åˆ†æä¼šåŒ…å«ï¼šç”¨æˆ·æ„å›¾ã€è¯­ä¹‰ç›¸å…³æ€§ã€æ•°æ®ç»Ÿè®¡æ˜¾è‘—æ€§åˆ†æã€‚")
    
    if not df_term.empty:
        c_term = 'å®¢æˆ·æœç´¢è¯'
        c_spend = 'èŠ±è´¹'
        c_orders = '7å¤©æ€»è®¢å•æ•°(#)'
        c_clicks = 'ç‚¹å‡»é‡'
        
        if c_term in df_term.columns:
            df_term[c_spend] = pd.to_numeric(df_term[c_spend], errors='coerce').fillna(0)
            df_term[c_orders] = pd.to_numeric(df_term[c_orders], errors='coerce').fillna(0)
            df_term[c_clicks] = pd.to_numeric(df_term[c_clicks], errors='coerce').fillna(0)
            
            mask = (df_term[c_orders] == 0) & (df_term[c_spend] > 0)
            review_df = df_term[mask].sort_values(by=c_spend, ascending=False).head(10)
            
            if not review_df.empty:
                for idx, row in review_df.iterrows():
                    with st.expander(f"ğŸ“ {row[c_term]} (èŠ±è´¹: ${row[c_spend]:.2f})", expanded=True):
                        c1, c2 = st.columns([1, 4])
                        
                        with c1:
                            st.write("#### ä½ çš„å†³å®šï¼š")
                            if st.button("âŒ å¦å®š (ç”Ÿæˆåˆ†æ)", key=f"n_{idx}", type="primary"):
                                reasoning = generate_and_save_ai_thought(deepseek_key, row[c_term], row[c_spend], row[c_clicks], 0, "Negative")
                                if reasoning:
                                    st.session_state[f"reason_{idx}"] = reasoning
                            
                            st.write("") # Spacer
                            if st.button("ğŸ‘€ è§‚å¯Ÿ (ç”Ÿæˆåˆ†æ)", key=f"k_{idx}"):
                                reasoning = generate_and_save_ai_thought(deepseek_key, row[c_term], row[c_spend], row[c_clicks], 0, "Keep")
                                if reasoning:
                                    st.session_state[f"reason_{idx}"] = reasoning
                        
                        with c2:
                            # åŠ¨æ€æ˜¾ç¤º AI çš„æ€è€ƒç»“æœ
                            if f"reason_{idx}" in st.session_state:
                                st.markdown(f"""
                                <div class="ai-thought">
                                    <b>ğŸ¤– AI æ·±åº¦åˆ†ææŠ¥å‘Šï¼š</b><br>
                                    {st.session_state[f"reason_{idx}"]}
                                </div>
                                """, unsafe_allow_html=True)
                            else:
                                st.caption("ğŸ‘ˆ ç‚¹å‡»å·¦ä¾§æŒ‰é’®ï¼Œè®© AI ç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Š...")
                                
            else: st.success("æ²¡æœ‰å‘ç°é«˜èŠ±è´¹0è½¬åŒ–çš„è¯ã€‚")
    else: st.info("è¯·ä¸Šä¼  Search Term è¡¨æ ¼")

# --- Tab 2: çœ‹æ¿ ---
with tab2:
    st.subheader("ğŸ“ˆ è´¦æˆ·é€è§†")
    if bulk_ready:
        t_spend = df_kws[bk_cols['spend']].sum()
        t_sales = df_kws[bk_cols['sales']].sum()
        m1, m2 = st.columns(2)
        m1.metric("æ€»èŠ±è´¹", f"${t_spend:,.2f}")
        m2.metric("æ€»é”€å”®é¢", f"${t_sales:,.2f}")
        
        chart_data = df_kws[df_kws[bk_cols['spend']]>0]
        st.scatter_chart(chart_data, x=bk_cols['spend'], y=bk_cols['sales'], size=bk_cols['clicks'], color='ACoS')
    else: st.info("ç­‰å¾… Bulk æ•°æ®...")

# --- Tab 3: ç«ä»· ---
with tab3:
    st.subheader("ğŸ’° ç«ä»·ä¼˜åŒ–")
    if bulk_ready:
        bad_kws = df_kws[(df_kws[bk_cols['orders']] > 0) & (df_kws['ACoS'] > target_acos)].sort_values(by='ACoS', ascending=False).head(50)
        if not bad_kws.empty:
            show_df = bad_kws[[bk_cols['kw'], bk_cols['bid'], 'ACoS', bk_cols['spend'], bk_cols['sales']]].copy()
            show_df['å»ºè®®ç«ä»·'] = show_df[bk_cols['bid']] * 0.8
            st.dataframe(show_df, column_config={"ACoS": st.column_config.ProgressColumn(format="%.2f", max_value=2)}, use_container_width=True)
        else: st.success("ç«ä»·å¥åº·")
    else: st.info("ç­‰å¾… Bulk æ•°æ®")

# --- Tab 4: é»„é‡‘è¯ ---
with tab4:
    st.subheader("ğŸ† é»„é‡‘è¯")
    if bulk_ready:
        gold_df = df_kws[(df_kws[bk_cols['orders']] >= 2) & (df_kws['ACoS'] > 0) & (df_kws['ACoS'] < gold_acos)].sort_values(by=bk_cols['sales'], ascending=False).head(50)
        if not gold_df.empty:
            show_df = gold_df[[bk_cols['kw'], bk_cols['bid'], 'ACoS', bk_cols['sales']]].copy()
            show_df['å»ºè®®ç«ä»·'] = show_df[bk_cols['bid']] * 1.2
            st.dataframe(show_df, column_config={"ACoS": st.column_config.ProgressColumn(format="%.2f", max_value=0.5)}, use_container_width=True)
        else: st.info("æš‚æ— é»„é‡‘è¯")
    else: st.info("ç­‰å¾… Bulk æ•°æ®")

# --- Tab 5: å…³è” ---
with tab5:
    st.subheader("ğŸ’« å…³è”åˆ†æ")
    if not df_term.empty:
        c_halo = '7å¤©å†…å…¶ä»–SKUé”€å”®é‡(#)'
        if c_halo in df_term.columns:
            df_term[c_halo] = pd.to_numeric(df_term[c_halo], errors='coerce').fillna(0)
            halo = df_term[df_term[c_halo]>0].sort_values(by=c_halo, ascending=False).head(20)
            if not halo.empty: st.dataframe(halo[['å®¢æˆ·æœç´¢è¯', c_halo, 'èŠ±è´¹']], use_container_width=True)
            else: st.info("æ— å…³è”è®¢å•")