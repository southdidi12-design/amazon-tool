import streamlit as st
import pandas as pd
import io
import requests
import json

# === ç½‘é¡µé…ç½® ===
st.set_page_config(page_title="äºšé©¬é€Šå¹¿å‘Šå…¨èƒ½ç‹ (ç­–ç•¥æ‰§è¡Œç‰ˆ)", layout="wide", page_icon="âš–ï¸")
st.title("âš–ï¸ Amazon å¹¿å‘Šä¼˜åŒ–å…¨èƒ½ç‹ (å››å¤§ç­–ç•¥ç‰ˆ)")
st.info("ğŸ’¡ å½“å‰æ‰§è¡Œç­–ç•¥ï¼šæ¸…ç†æµªè´¹ã€ä¿æŠ¤åˆ©æ¶¦ã€é™æœ¬å¢æ•ˆã€è‡ªåŠ¨æ‹“è¯")

# === ä¾§è¾¹æ è®¾ç½® ===
st.sidebar.header("ğŸ”‘ AI è®¾ç½®")
# é»˜è®¤Keyå·²é¢„å¡«
default_key = "sk-55cc3f56742f4e43be099c9489e02911"
deepseek_key = st.sidebar.text_input("DeepSeek API Key", value=default_key, type="password")
product_name = st.sidebar.text_input("äº§å“åç§°", value="LED Makeup Mirror")

st.sidebar.header("âš™ï¸ ç­–ç•¥é˜ˆå€¼å¾®è°ƒ")
waste_spend = st.sidebar.number_input("ğŸ—‘ï¸ æ¸…ç†æµªè´¹: èŠ±è´¹è¶…($)", value=20.0, step=5.0)
scale_acos = st.sidebar.slider("ğŸš€ ä¿æŠ¤åˆ©æ¶¦: ACoS ä½äº(%)", 5, 30, 20) / 100
scale_bid_inc = st.sidebar.number_input("ğŸ“ˆ æä»·å¹…åº¦", value=1.10, step=0.05, help="1.1 è¡¨ç¤ºæ¶¨10%")

control_acos = st.sidebar.slider("ğŸ“‰ é™æœ¬å¢æ•ˆ: ACoS é«˜äº(%)", 20, 80, 40) / 100
control_bid_dec = st.sidebar.number_input("ğŸ“‰ é™ä»·å¹…åº¦", value=0.85, step=0.05, help="0.85 è¡¨ç¤ºé™15%")

mining_orders = st.sidebar.number_input("â›ï¸ æ‹“è¯æ ‡å‡†: è®¢å•è¶…è¿‡(å•)", value=3, step=1)

# === ä¸Šä¼ åŒºåŸŸ ===
st.write("---")
c1, c2 = st.columns(2)
with c1:
    file_bulk = st.file_uploader("ğŸ“‚ 1. æ‹–å…¥ã€æ‰¹é‡æ“ä½œè¡¨æ ¼ã€‘(Bulk)", type=['xlsx'], key="bulk")
with c2:
    file_term = st.file_uploader("ğŸ“‚ 2. æ‹–å…¥ã€æœç´¢è¯æŠ¥å‘Šã€‘(Search Term)", type=['xlsx'], key="term")
st.write("---")

# === DeepSeek å‡½æ•° ===
def call_deepseek_analysis(api_key, product, neg_data, bid_data, mining_data):
    url = "https://api.deepseek.com/chat/completions"
    prompt = f"""
    æˆ‘æ˜¯äºšé©¬é€Šå–å®¶ï¼Œäº§å“æ˜¯ã€{product}ã€‘ã€‚è¯·æ ¹æ®æˆ‘çš„å››å¤§ç­–ç•¥åˆ†ææ•°æ®ï¼š

    1. ã€æ¸…ç†æµªè´¹ (å»ºè®®å¦å®š)ã€‘ï¼š
    {neg_data.to_string(index=False)}
    * ç‚¹è¯„è¿™äº›è¯çš„ä¸ç›¸å…³æ€§ã€‚

    2. ã€ä¿æŠ¤åˆ©æ¶¦ & é™æœ¬å¢æ•ˆ (ç«ä»·è°ƒæ•´)ã€‘ï¼š
    {bid_data.to_string(index=False)}
    * åˆ†ææä»·è¯çš„æ½œåŠ›ï¼Œä»¥åŠé™ä»·è¯çš„é—®é¢˜æ‰€åœ¨ã€‚

    3. ã€æ‹“è¯å»ºè®® (é»‘é©¬è¯)ã€‘ï¼š
    {mining_data.to_string(index=False)}
    * è¿™äº›è¯å€¼å¾—æ‰“æ‰‹åŠ¨ç²¾å‡†å—ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ

    è¯·ç”¨ Markdown æ ¼å¼ï¼Œç®€ç»ƒç›´æ¥ï¼Œç»™å‡ºä¸“å®¶çº§å»ºè®®ã€‚
    """
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    data = {
        "model": "deepseek-chat",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.5
    }
    try:
        res = requests.post(url, headers=headers, json=data)
        if res.status_code == 200: return res.json()['choices'][0]['message']['content']
        return f"AI æŠ¥é”™: {res.text}"
    except Exception as e: return f"é”™è¯¯: {e}"

# === 1ï¸âƒ£ æ‰¹é‡è¡¨æ ¼åˆ†æ (Scale Up & Cost Control) ===
ai_bid_summary = pd.DataFrame()

if file_bulk:
    try:
        dfs = pd.read_excel(file_bulk, sheet_name=None, engine='openpyxl')
        bulk_df = pd.DataFrame()
        found_sheet_name = ""

        # ç²¾å‡†æ‰¾è¡¨
        for name, df in dfs.items():
            df.columns = df.columns.astype(str).str.strip()
            cols = df.columns.tolist()
            if ('å®ä½“å±‚çº§' in cols or 'Record Type' in cols) and \
               ('å…³é”®è¯æ–‡æœ¬' in cols or 'Keyword Text' in cols):
                bulk_df = df
                found_sheet_name = name
                break
        
        if bulk_df.empty:
            st.error("âŒ Bulkæ–‡ä»¶æ²¡æ‰¾åˆ°æ•°æ®è¡¨ï¼è¯·æ£€æŸ¥ã€‚")
        else:
            st.success(f"âœ… ç«ä»·ç­–ç•¥æ‰§è¡Œä¸­... (æ•°æ®æº: {found_sheet_name})")

            # åˆ—åæ˜ å°„
            col_map = {
                'å®ä½“å±‚çº§': 'Record Type', 'Record Type': 'Record Type',
                'å¹¿å‘Šæ´»åŠ¨åç§°ï¼ˆä»…ä¾›å‚è€ƒï¼‰': 'Campaign', 'å¹¿å‘Šæ´»åŠ¨åç§°': 'Campaign',
                'å¹¿å‘Šç»„åç§°ï¼ˆä»…ä¾›å‚è€ƒï¼‰': 'Ad Group', 'å¹¿å‘Šç»„åç§°': 'Ad Group',
                'åŒ¹é…ç±»å‹': 'Match Type', 'Match Type': 'Match Type',
                'å…³é”®è¯æ–‡æœ¬': 'Keyword', 'Keyword Text': 'Keyword',
                'ç«ä»·': 'Max Bid', 'Max Bid': 'Max Bid',
                'èŠ±è´¹': 'Spend', 'Spend': 'Spend',
                'é”€é‡': 'Sales', 'Sales': 'Sales',
                'è®¢å•æ•°é‡': 'Orders', 'Orders': 'Orders',
                'å±•ç¤ºé‡': 'Impressions', 'Impressions': 'Impressions',
                'ç‚¹å‡»é‡': 'Clicks', 'Clicks': 'Clicks',
                'æ‹“å±•å•†å“æŠ•æ”¾ç¼–å·': 'Targeting', 'å•†å“æŠ•æ”¾ ID': 'Targeting ID'
            }
            df_clean = bulk_df.rename(columns=col_map)
            df_clean = df_clean.loc[:, ~df_clean.columns.duplicated()]

            # ç­›é€‰ Keyword / Product Targeting
            df_clean['Record Type'] = df_clean['Record Type'].astype(str)
            mask = df_clean['Record Type'].str.contains('å…³é”®è¯|Keyword|å•†å“å®šå‘|Product Targeting', case=False, na=False)
            data_bid = df_clean[mask].copy()

            # æ•´ç†æ•°æ®
            if 'Keyword' not in data_bid.columns: data_bid['Keyword'] = None
            data_bid['Target'] = data_bid['Keyword']
            if 'Targeting' in data_bid.columns: 
                data_bid['Target'] = data_bid['Target'].fillna(data_bid['Targeting'])

            for c in ['Spend', 'Sales', 'Orders', 'Max Bid', 'Clicks']:
                if c in data_bid.columns: data_bid[c] = pd.to_numeric(data_bid[c], errors='coerce').fillna(0)

            # è®¡ç®—åŸºç¡€æŒ‡æ ‡
            data_bid['ACoS'] = data_bid['Spend'] / data_bid['Sales']
            data_bid['ACoS'] = data_bid['ACoS'].fillna(0)
            data_bid['CVR'] = data_bid['Orders'] / data_bid['Clicks']
            data_bid['CVR'] = data_bid['CVR'].fillna(0)

            # === è®¡ç®—å¹¿å‘Šç»„å¹³å‡è½¬åŒ–ç‡ (Avg CVR) ===
            # æŒ‰å¹¿å‘Šç»„åˆ†ç»„ï¼Œè®¡ç®—è½¬åŒ–ç‡å‡å€¼
            ad_group_cvr = data_bid.groupby('Ad Group')['CVR'].mean().reset_index()
            ad_group_cvr.rename(columns={'CVR': 'Avg_Group_CVR'}, inplace=True)
            
            # åˆå¹¶å›å»
            data_bid = pd.merge(data_bid, ad_group_cvr, on='Ad Group', how='left')

            # === ç­–ç•¥å®æ–½ ===
            data_bid['ç­–ç•¥åŠ¨ä½œ'] = 'ä¿æŒ'
            data_bid['å»ºè®®æ–°ç«ä»·'] = data_bid['Max Bid']

            # è§„åˆ™ 2: ä¿æŠ¤åˆ©æ¶¦ (Scale Up)
            # ACoS < 20% AND CVR > Avg_Group_CVR
            mask_scale = (data_bid['ACoS'] < scale_acos) & \
                         (data_bid['ACoS'] > 0) & \
                         (data_bid['CVR'] > data_bid['Avg_Group_CVR'])
            
            data_bid.loc[mask_scale, 'ç­–ç•¥åŠ¨ä½œ'] = 'ğŸš€ æä»·æ‰©é‡'
            data_bid.loc[mask_scale, 'å»ºè®®æ–°ç«ä»·'] = data_bid.loc[mask_scale, 'Max Bid'] * scale_bid_inc

            # è§„åˆ™ 3: é™æœ¬å¢æ•ˆ (Cost Control)
            # ACoS > 40% AND Orders > 2
            mask_control = (data_bid['ACoS'] > control_acos) & (data_bid['Orders'] > 2)
            
            data_bid.loc[mask_control, 'ç­–ç•¥åŠ¨ä½œ'] = 'ğŸ“‰ é™ä»·æ§åˆ¶'
            data_bid.loc[mask_control, 'å»ºè®®æ–°ç«ä»·'] = data_bid.loc[mask_control, 'Max Bid'] * control_bid_dec

            # ç»“æœå±•ç¤º
            action_df = data_bid[data_bid['ç­–ç•¥åŠ¨ä½œ'] != 'ä¿æŒ'].copy()
            
            # å‡†å¤‡ç»™AIçš„æ•°æ®
            ai_bid_summary = action_df[['Target', 'ACoS', 'CVR', 'ç­–ç•¥åŠ¨ä½œ']].head(6)

            st.subheader("ğŸ“Š ç«ä»·ç­–ç•¥æ‰§è¡Œç»“æœ")
            if not action_df.empty:
                c_up, c_down = st.tabs(["ğŸš€ éœ€æä»· (ä¼˜è´¨è¯)", "ğŸ“‰ éœ€é™ä»· (ä½æ•ˆè¯)"])
                
                with c_up:
                    df_up = action_df[action_df['ç­–ç•¥åŠ¨ä½œ'].str.contains('æä»·')]
                    if not df_up.empty:
                        st.dataframe(df_up[['Campaign', 'Ad Group', 'Target', 'Max Bid', 'å»ºè®®æ–°ç«ä»·', 'Orders', 'ACoS', 'CVR', 'Avg_Group_CVR']]
                                     .style.format({'ACoS': '{:.1%}', 'CVR': '{:.1%}', 'Avg_Group_CVR': '{:.1%}', 'Max Bid': '{:.2f}', 'å»ºè®®æ–°ç«ä»·': '{:.2f}'}), 
                                     use_container_width=True)
                    else:
                        st.info("æš‚æ— æ»¡è¶³ã€æä»·ã€‘æ¡ä»¶çš„ä¼˜è´¨è¯ã€‚")

                with c_down:
                    df_down = action_df[action_df['ç­–ç•¥åŠ¨ä½œ'].str.contains('é™ä»·')]
                    if not df_down.empty:
                        st.dataframe(df_down[['Campaign', 'Ad Group', 'Target', 'Max Bid', 'å»ºè®®æ–°ç«ä»·', 'Orders', 'ACoS']]
                                     .style.format({'ACoS': '{:.1%}', 'Max Bid': '{:.2f}', 'å»ºè®®æ–°ç«ä»·': '{:.2f}'}), 
                                     use_container_width=True)
                    else:
                        st.info("æš‚æ— æ»¡è¶³ã€é™ä»·ã€‘æ¡ä»¶çš„è¯ã€‚")
            else:
                st.success("âœ… å½“å‰å¹¿å‘Šè¡¨ç°å¹³ç¨³ï¼Œæ— éœ€æ ¹æ®æ‰€è®¾è§„åˆ™è¿›è¡Œè°ƒæ•´ã€‚")

    except Exception as e:
        st.error(f"Bulkå¤„ç†é”™è¯¯: {e}")

# === 2ï¸âƒ£ æœç´¢è¯æŠ¥å‘Šåˆ†æ (Waste & Mining) ===
ai_waste_data = pd.DataFrame()
ai_mining_data = pd.DataFrame()

if file_term:
    try:
        term_df = pd.read_excel(file_term, engine='openpyxl')
        term_df.columns = term_df.columns.astype(str).str.strip()

        st_col_map = {
            'å®¢æˆ·æœç´¢è¯': 'Search Term', 'Customer Search Term': 'Search Term',
            'å¹¿å‘Šæ´»åŠ¨åç§°': 'Campaign', 'Campaign Name': 'Campaign',
            'å¹¿å‘Šç»„åç§°': 'Ad Group', 'Ad Group Name': 'Ad Group',
            'åŒ¹é…ç±»å‹': 'Match Type', 'Match Type': 'Match Type',
            'èŠ±è´¹': 'Spend', 'Spend': 'Spend',
            'ç‚¹å‡»é‡': 'Clicks', 'Clicks': 'Clicks',
            '7å¤©æ€»è®¢å•æ•°(#)': 'Orders', '7å¤©æ€»è®¢å•æ•°': 'Orders', 'è®¢å•æ•°é‡': 'Orders',
            'å¹¿å‘ŠæŠ•å…¥äº§å‡ºæ¯” (ACOS) æ€»è®¡': 'ACoS'
        }
        term_df = term_df.rename(columns=st_col_map)
        term_df = term_df.loc[:, ~term_df.columns.duplicated()]

        for c in ['Spend', 'Orders', 'Clicks', 'ACoS']:
             if c in term_df.columns: term_df[c] = pd.to_numeric(term_df[c], errors='coerce').fillna(0)

        if 'Orders' in term_df.columns:
            # è§„åˆ™ 1: æ¸…ç†æµªè´¹ (Negative Match)
            # Spend > $20 AND Orders = 0
            mask_waste = (term_df['Spend'] > waste_spend) & (term_df['Orders'] == 0)
            waste_df = term_df[mask_waste].copy()
            waste_df['å»ºè®®æ“ä½œ'] = 'æ·»åŠ å¦å®šç²¾å‡†'
            
            ai_waste_data = waste_df[['Search Term', 'Spend', 'Clicks']].head(5)

            # è§„åˆ™ 4: æ‹“è¯é€»è¾‘ (Keyword Mining)
            # Orders > 3 (ä¸”å‡è®¾éç²¾ç¡®åŒ¹é…æ‰æç¤ºï¼Œè¿™é‡Œç®€å•å±•ç¤ºæ‰€æœ‰é«˜è½¬åŒ–è¯)
            mask_mining = (term_df['Orders'] >= mining_orders)
            # æ’é™¤å·²ç»æ˜¯ç²¾ç¡®åŒ¹é…çš„ (Match Type == Exact æˆ– -)
            # æ³¨æ„ï¼šè‡ªåŠ¨å¹¿å‘Š Match Type å¯èƒ½æ˜¯ '-', ä¹Ÿå¯ä»¥æ‹“ã€‚æ‰‹åŠ¨ç²¾å‡†é€šå¸¸æ˜¾ç¤º 'EXACT'
            # è¿™é‡Œç®€å•èµ·è§ï¼Œåªè¦å‡ºå•å¤šï¼Œéƒ½åˆ—å‡ºæ¥ä¾›äººå·¥å®¡æ ¸
            mining_df = term_df[mask_mining].copy()
            mining_df['å»ºè®®æ“ä½œ'] = 'æŠ•æ”¾æ‰‹åŠ¨ç²¾å‡†'
            
            ai_mining_data = mining_df[['Search Term', 'Orders', 'ACoS']].head(5)

            st.subheader("ğŸ›¡ï¸ å¦è¯ & æ‹“è¯å»ºè®®")
            t_neg, t_mine = st.tabs(["ğŸ—‘ï¸ å»ºè®®å¦å®š (æ¸…ç†æµªè´¹)", "â›ï¸ å»ºè®®æ‹“è¯ (é»‘é©¬æŒ–æ˜)"])

            with t_neg:
                if not waste_df.empty:
                    st.error(f"ğŸš¨ å‘ç° {len(waste_df)} ä¸ªæµªè´¹èµ„é‡‘çš„æœç´¢è¯ï¼")
                    st.dataframe(waste_df[['Campaign', 'Ad Group', 'Search Term', 'Spend', 'Clicks', 'å»ºè®®æ“ä½œ']]
                                 .style.format({'Spend': '{:.2f}'}), use_container_width=True)
                else:
                    st.success("âœ… æ²¡æœ‰å‘ç°èŠ±è´¹è¶…æ ‡ä¸”ä¸å‡ºå•çš„è¯ã€‚")

            with t_mine:
                if not mining_df.empty:
                    st.success(f"ğŸ’ å‘ç° {len(mining_df)} ä¸ªé«˜è½¬åŒ–æœç´¢è¯ï¼")
                    st.dataframe(mining_df[['Campaign', 'Ad Group', 'Search Term', 'Orders', 'ACoS', 'å»ºè®®æ“ä½œ']], 
                                 use_container_width=True)
                else:
                    st.info(f"æš‚æ— è®¢å•æ•°è¶…è¿‡ {mining_orders} çš„é»‘é©¬è¯ã€‚")

    except Exception as e:
        st.error(f"æœç´¢è¯æŠ¥å‘Šé”™è¯¯: {e}")

# === 3. AI ç»¼åˆæ±‡æŠ¥ ===
if file_bulk and file_term:
    st.write("---")
    st.subheader("ğŸ¤– DeepSeek æˆ˜ç•¥é¡¾é—®")
    if st.button("ç”Ÿæˆæˆ˜ç•¥åˆ†ææŠ¥å‘Š"):
        if not deepseek_key:
             st.error("Key ä¸ºç©ºï¼")
        else:
            with st.spinner("AI æ­£åœ¨æ ¹æ®å››å¤§ç­–ç•¥åˆ†æå…¨ç›˜æ•°æ®..."):
                report = call_deepseek_analysis(deepseek_key, product_name, ai_waste_data, ai_bid_summary, ai_mining_data)
                st.markdown(report)
