import json
import re
import time
from datetime import date, datetime, timedelta

import pandas as pd

from .amazon_api import (
    create_sp_keywords,
    create_sp_negative_keywords,
    get_amazon_session_and_headers,
    get_row_value,
    list_sp_campaign_negative_keywords,
    list_sp_campaigns,
    list_sp_keywords,
    list_sp_negative_keywords,
    list_sp_targets,
    update_campaign_budget,
    update_sp_campaign_bidding,
    update_sp_keyword_bids,
    update_sp_target_bids,
)
from .config import (
    AUTO_NEGATIVE_ACOS_MULT_KEY,
    AUTO_NEGATIVE_CLICKS_KEY,
    AUTO_NEGATIVE_DAYS_KEY,
    AUTO_NEGATIVE_ENABLED_KEY,
    AUTO_NEGATIVE_LAST_RUN_KEY,
    AUTO_NEGATIVE_LEVEL_KEY,
    AUTO_NEGATIVE_MATCH_KEY,
    AUTO_NEGATIVE_PROTECT_KEY,
    AUTO_NEGATIVE_PROTECT_MODE_KEY,
    AUTO_NEGATIVE_SPEND_KEY,
    MIN_BUDGET,
    MIN_BID,
    REPORT_POLL_MAX,
    REPORT_POLL_SLEEP_SECONDS,
    get_auto_ai_campaign_daily_budget,
    get_auto_ai_campaign_whitelist,
    get_real_today,
)
from .db import (
    db_write_lock,
    get_db_connection,
    get_system_value,
    save_auto_negative_keywords,
    set_system_value,
    update_auto_negative_status,
)
from .sync import sync_asin_report, sync_product_ads, sync_sp_adgroups

# --- 2. DeepSeek AI ---
try:
    import openai

    HAS_OPENAI = True
except Exception:
    HAS_OPENAI = False


def deepseek_audit(api_key, row, proposed_value, rule_reason, is_star, value_label):
    if not HAS_OPENAI or not api_key:
        return "Êú™ÂÆ°Ê†∏", proposed_value
    try:
        client = openai.OpenAI(api_key=api_key, base_url="https://api.deepseek.com")
        role = "„Äê‚≠ê‰∏ªÊé®Ê¨æ„Äë(Êä¢ÊéíÂêçÁ≠ñÁï•)" if is_star else "„ÄêÊôÆÈÄöÊ¨æ„Äë(‰øùÂà©Ê∂¶Á≠ñÁï•)"
        prompt = f"""
        ÊàëÊòØ‰∫öÈ©¨ÈÄäËøêËê•„ÄÇ
        ÂØπË±°Ôºö{row['campaign_name']} ({role})
        Êï∞ÊçÆÔºöËä±Ë¥π${row['cost']}, ACOS {row['acos']*100:.1f}%„ÄÇ
        ÁÆóÊ≥ïÂª∫ËÆÆÔºö{value_label}Ë∞ÉÊï¥‰∏∫ ${proposed_value} (ÁêÜÁî±: {rule_reason})
        ËØ∑ÂÆ°Ê†∏ËØ•Âª∫ËÆÆÊòØÂê¶ÂêàÁêÜÔºü
        ËøîÂõû JSON: {{"comment": "ÁêÜÁî±", "final_value": Êï∞Â≠ó}}
        """
        response = client.chat.completions.create(
            model="deepseek-chat", messages=[{"role": "user", "content": prompt}], temperature=0.1
        )
        res = json.loads(re.search(r"\{.*\}", response.choices[0].message.content, re.DOTALL).group())
        final_value = res.get("final_value", res.get("final_bid", proposed_value))
        comment = res.get("comment", "")
        return f"AI: {comment}".strip(), float(final_value)
    except Exception:
        return "AIÊä•Èîô", proposed_value


def _chunked(items, size=100):
    for i in range(0, len(items), size):
        yield items[i : i + size]


INVALID_COLUMNS_ERROR = "columns includes invalid values"
AUTO_NEGATIVE_PENDING_KEY = "auto_negative_pending_report"
AUTO_KEYWORD_PENDING_KEY = "auto_keyword_pending_report"
SEARCH_COST_KEYS = ["cost", "spend"]
SEARCH_SALES_KEYS = [
    "sales7d",
    "sales14d",
    "sales1d",
    "sales",
    "attributedsales14d",
    "attributedsales7d",
    "attributedsales1d",
]
SEARCH_ORDER_KEYS = [
    "purchases7d",
    "purchases14d",
    "purchases1d",
    "orders",
    "attributedconversions14d",
    "attributedconversions7d",
    "attributedconversions1d",
]


def _parse_allowed_columns(text):
    patterns = [
        r"Allowed values:\s*\((.*?)\)",
        r"Allowed values:\s*\[(.*?)\]",
    ]
    for pat in patterns:
        match = re.search(pat, text, re.DOTALL)
        if match:
            raw = match.group(1)
            return [c.strip() for c in raw.split(",") if c.strip()]
    match = re.search(r"Allowed values:\s*([^\r\n]+)", text)
    if match:
        raw = match.group(1)
        raw = raw.replace("(", "").replace(")", "").replace("[", "").replace("]", "")
        raw = raw.split(".")[0]
        return [c.strip() for c in raw.split(",") if c.strip()]
    return []


def _resolve_search_columns(allowed):
    columns = []
    for req in ["searchTerm", "campaignId", "adGroupId"]:
        if req in allowed:
            columns.append(req)
    for optional in ["keywordId", "keywordText", "matchType", "clicks", "impressions"]:
        if optional in allowed and optional not in columns:
            columns.append(optional)
    for key in SEARCH_COST_KEYS:
        if key in allowed and key not in columns:
            columns.append(key)
            break
    sales_keys = []
    for key in SEARCH_SALES_KEYS:
        if key in allowed and key not in columns:
            columns.append(key)
            sales_keys.append(key)
            break
    orders_keys = []
    for key in SEARCH_ORDER_KEYS:
        if key in allowed and key not in columns:
            columns.append(key)
            orders_keys.append(key)
            break
    return columns, sales_keys, orders_keys


def _fetch_search_term_report(session, headers, start_date, end_date):
    columns = [
        "searchTerm",
        "campaignId",
        "adGroupId",
        "keywordId",
        "keywordText",
        "matchType",
        "cost",
        "clicks",
        "impressions",
        "sales7d",
        "purchases7d",
    ]
    sales_keys = ["sales7d", "sales14d", "sales1d", "sales"]
    orders_keys = ["purchases7d", "purchases14d", "purchases1d", "orders"]

    def _request(cols, s_keys, o_keys):
        req = session.post(
            "https://advertising-api.amazon.com/reporting/reports",
            headers=headers,
            json={
                "startDate": start_date,
                "endDate": end_date,
                "configuration": {
                    "adProduct": "SPONSORED_PRODUCTS",
                    "groupBy": ["searchTerm"],
                    "columns": cols,
                    "reportTypeId": "spSearchTerm",
                    "timeUnit": "DAILY",
                    "format": "GZIP_JSON",
                },
            },
        )
        if req.status_code in [200, 201, 202]:
            rid = req.json().get("reportId")
        elif "duplicate" in req.text.lower():
            rid = req.json().get("detail", "").split(":")[-1].strip()
        elif req.status_code == 400 and INVALID_COLUMNS_ERROR in req.text:
            allowed = _parse_allowed_columns(req.text)
            if allowed:
                new_cols, new_sales, new_orders = _resolve_search_columns(allowed)
                if new_cols:
                    return _request(new_cols, new_sales, new_orders)
            return None, s_keys, o_keys, f"search term invalid columns"
        else:
            return None, s_keys, o_keys, f"search term create failed {req.status_code}: {req.text[:200]}"
        return rid, s_keys, o_keys, None

    return _request(columns, sales_keys, orders_keys)


def _check_report_once(session, headers, report_id):
    try:
        chk = session.get(f"https://advertising-api.amazon.com/reporting/reports/{report_id}", headers=headers)
        if chk.status_code != 200:
            return None, f"status {chk.status_code}: {chk.text[:200]}"
        payload = chk.json()
        status = payload.get("status")
        if status == "COMPLETED":
            url = payload.get("url")
            if url:
                data = pd.read_json(url, compression="gzip")
                return data, None
            return None, "completed without url"
        if status in ["FAILED", "CANCELLED"]:
            return None, f"status {status}"
        return None, "pending"
    except Exception as exc:
        return None, f"exception: {exc}"


def _wait_for_report(session, headers, report_id, max_polls=10):
    for _ in range(max_polls):
        time.sleep(REPORT_POLL_SLEEP_SECONDS)
        data, err = _check_report_once(session, headers, report_id)
        if err == "pending":
            continue
        return data, err
    return None, "pending"


def _load_pending_report(key=None):
    if not key:
        key = AUTO_NEGATIVE_PENDING_KEY
    raw = get_system_value(key)
    if not raw:
        return None
    try:
        payload = json.loads(raw)
    except Exception:
        return None
    return payload if isinstance(payload, dict) else None


def _save_pending_report(report_id, start_date, end_date, sales_keys, orders_keys, key=None):
    if not key:
        key = AUTO_NEGATIVE_PENDING_KEY
    payload = {
        "report_id": report_id,
        "start": start_date,
        "end": end_date,
        "sales_keys": sales_keys,
        "orders_keys": orders_keys,
        "ts": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    }
    set_system_value(key, json.dumps(payload))


def _clear_pending_report(key=None):
    if not key:
        key = AUTO_NEGATIVE_PENDING_KEY
    set_system_value(key, "")


def _get_auto_negative_config(cfg):
    defaults = {
        "enabled": False,
        "level": "adgroup",
        "match": "NEGATIVE_EXACT",
        "spend": 3.0,
        "clicks": 8,
        "acos_mult": 1.5,
        "days": 7,
        "protect_terms": [],
        "protect_mode": "contains",
    }
    if cfg:
        defaults.update(cfg)
    return defaults


def _normalize_negative_match(match_type):
    if not match_type:
        return "NEGATIVE_EXACT"
    mt = str(match_type).strip().upper()
    if mt in ["NEGATIVE_EXACT", "NEGATIVE_PHRASE"]:
        return mt
    if mt in ["EXACT", "PHRASE"]:
        return f"NEGATIVE_{mt}"
    if mt in ["NEGATIVEEXACT"]:
        return "NEGATIVE_EXACT"
    if mt in ["NEGATIVEPHRASE"]:
        return "NEGATIVE_PHRASE"
    return mt


def _normalize_positive_match(match_type):
    if not match_type:
        return ""
    mt = str(match_type).strip().upper()
    if mt in ["EXACT", "PHRASE", "BROAD"]:
        return mt
    if mt in ["EXACT_MATCH"]:
        return "EXACT"
    if mt in ["PHRASE_MATCH"]:
        return "PHRASE"
    if mt in ["BROAD_MATCH"]:
        return "BROAD"
    return mt


def _is_asin_term(term):
    t = str(term or "").strip().upper()
    if len(t) != 10:
        return False
    if not re.match(r"^[A-Z0-9]{10}$", t):
        return False
    return t.startswith("B")


def _parse_protect_terms(raw):
    if not raw:
        return []
    if isinstance(raw, list):
        terms = raw
    else:
        text = str(raw)
        parts = []
        for chunk in text.replace(",", "\n").replace(";", "\n").splitlines():
            chunk = chunk.strip()
            if chunk:
                parts.append(chunk)
        terms = parts
    return [t.lower() for t in terms if str(t).strip()]


def _is_protected_term(term, protect_terms, mode):
    if not protect_terms:
        return False
    t = str(term or "").strip().lower()
    if not t:
        return False
    if str(mode).lower() == "exact":
        return t in protect_terms
    return any(p in t for p in protect_terms)

def run_optimization_logic(
    base_target_acos, base_max_bid, base_stop_loss, is_live_mode, deepseek_key, auto_negative_config=None
):
    conn = get_db_connection()
    logs = []
    session, headers = get_amazon_session_and_headers()
    live_note = ""
    if not session:
        if is_live_mode:
            is_live_mode = False
            live_note = " | Êó†APIÈÖçÁΩÆÔºåÂ∑≤ËΩ¨Ê®°Êãü"
        ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        reason = "Êó†APIÈÖçÁΩÆÔºåÊó†Ê≥ïÊãâÂèñÂÖ≥ÈîÆËØç/ÊäïÊîæ/ÂπøÂëä‰Ωç"
        with db_write_lock():
            conn.execute(
                "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                (ts, "Á≥ªÁªü", "SP Ëá™Âä®È©æÈ©∂", 0, 0, reason, "Â§±Ë¥•"),
            )
            conn.commit()
        conn.close()
        return logs
    try:
        sync_sp_adgroups(session, headers)
        sync_product_ads(session, headers)
    except Exception:
        pass
    today = get_real_today()
    start = (today - timedelta(days=7)).strftime("%Y-%m-%d")
    end = today.strftime("%Y-%m-%d")

    # ÂÖàÁ°Æ‰øù ASIN Êä•Ë°®ÊúâÊúÄËøë 7 Â§©Êï∞ÊçÆ
    try:
        row = conn.execute("SELECT MAX(date) FROM asin_reports").fetchone()
    except Exception:
        row = None
    latest_asin_date = None
    if row and row[0]:
        try:
            latest_asin_date = date.fromisoformat(row[0])
        except Exception:
            latest_asin_date = None
    target_end = today - timedelta(days=1)
    missing_days = 0
    if latest_asin_date is None:
        missing_days = 7
    else:
        missing_days = (target_end - latest_asin_date).days
        if missing_days < 0:
            missing_days = 0
        missing_days = min(missing_days, 7)

    if missing_days > 0:
        errors = []
        for i in range(1, missing_days + 1):
            d_str = (today - timedelta(days=i)).strftime("%Y-%m-%d")
            errors.extend(sync_asin_report(session, headers, d_str))
        if errors:
            ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            reason = errors[0]
            with db_write_lock():
                conn.execute(
                    "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                    (ts, "Á≥ªÁªü", "ASIN Êä•Ë°®ÂêåÊ≠•", 0, 0, reason, "Â§±Ë¥•"),
                )
                conn.commit()

    # === ASIN Á∫ßÂà´ÔºöÈ¢ÑÁÆó + ÁõÆÊ†á ACOS Ë∞ÉÊï¥ SP ÂÖ≥ÈîÆËØç/ÊäïÊîæ/ÂπøÂëä‰Ωç ===
    try:
        settings_df = pd.read_sql(
            "SELECT asin, sku, daily_budget, target_acos, budget_flex, is_star, ai_enabled FROM product_settings",
            conn,
        )
    except Exception:
        settings_df = pd.DataFrame()

    if not settings_df.empty:
        settings_df["asin"] = settings_df["asin"].fillna("").astype(str)
        settings_df["sku"] = settings_df["sku"].fillna("").astype(str)
        settings_df["daily_budget"] = settings_df["daily_budget"].fillna(0.0)
        settings_df["target_acos"] = settings_df["target_acos"].fillna(0.0)
        settings_df["budget_flex"] = settings_df["budget_flex"].fillna(0.0)
        settings_df["is_star"] = settings_df["is_star"].fillna(0).astype(bool)
        settings_df["ai_enabled"] = settings_df["ai_enabled"].fillna(1).astype(bool)

        asin_perf = pd.read_sql(
            f"""
            SELECT asin, sku, SUM(cost) as cost, SUM(sales) as sales
            FROM asin_reports
            WHERE date >= '{start}' AND date <= '{end}'
            GROUP BY asin, sku
            """,
            conn,
        )
        if not asin_perf.empty:
            asin_perf["asin"] = asin_perf["asin"].fillna("").astype(str)
            asin_perf["sku"] = asin_perf["sku"].fillna("").astype(str)
        else:
            asin_perf = pd.DataFrame(columns=["asin", "sku", "cost", "sales"])

        asin_data = pd.merge(settings_df, asin_perf, on=["asin", "sku"], how="left")
        asin_data["cost"] = asin_data["cost"].fillna(0.0)
        asin_data["sales"] = asin_data["sales"].fillna(0.0)
        asin_data["acos"] = asin_data.apply(
            lambda x: x["cost"] / x["sales"] if x["sales"] > 0 else 0, axis=1
        )

        days_window = 7
        asin_rules = {}
        asin_rules_by_asin = {}
        for _, row in asin_data.iterrows():
            if not row["ai_enabled"]:
                continue
            asin = str(row["asin"]).strip()
            if not asin:
                continue
            sku = str(row["sku"]).strip()
            daily_budget = float(row["daily_budget"] or 0)
            target_acos = float(row["target_acos"] or 0)
            budget_flex = float(row.get("budget_flex", 0) or 0)
            is_star = bool(row["is_star"])
            cost = float(row["cost"] or 0)
            sales = float(row["sales"] or 0)
            acos = float(row["acos"] or 0)
            if budget_flex < 0:
                budget_flex = 0.0
            if budget_flex > 100:
                budget_flex = 100.0

            if target_acos <= 0:
                target_acos = base_target_acos
            target_acos = target_acos * (1.5 if is_star else 1.0)
            stop_loss = base_stop_loss * (2.0 if is_star else 1.0)
            tag = "‚≠ê" if is_star else "ü•î"

            action = "‰øùÊåÅ"
            reasons = []
            acos_factor = 1.0

            if cost > stop_loss and sales == 0:
                action = "üõë Ê≠¢Êçü"
                reasons.append(f"{tag} 7Â§©ËÄó${cost:.0f}Êó†Âçï")
            elif sales > 0 and acos > (target_acos / 100):
                action = "üìâ Èôç‰ª∑"
                acos_factor = max((target_acos / 100) / acos, 0.8)
                reasons.append(f"{tag} ACOSÂÅèÈ´ò")
            elif sales > 0 and acos < (target_acos / 100 * (1.0 if is_star else 0.8)):
                action = "üöÄ ÊãìÈáè"
                acos_factor = 1.1
                reasons.append(f"{tag} Ë°®Áé∞‰ºòÂºÇ")

            budget_factor = 1.0
            if daily_budget > 0:
                avg_spend = cost / days_window
                budget_limit = daily_budget * (1.0 + budget_flex / 100.0)
                if avg_spend > budget_limit:
                    budget_factor = max(budget_limit / avg_spend, 0.5)
                    if budget_flex > 0:
                        reasons.append(f"Ë∂ÖÈ¢ÑÁÆó Êó•Âùá${avg_spend:.2f}/{daily_budget:.2f} (+{budget_flex:.0f}%)")
                    else:
                        reasons.append(f"Ë∂ÖÈ¢ÑÁÆó Êó•Âùá${avg_spend:.2f}/{daily_budget:.2f}")
                    if action == "‰øùÊåÅ":
                        action = "üìâ Èôç‰ª∑"

            if action == "‰øùÊåÅ" and budget_factor == 1.0 and acos_factor == 1.0:
                continue

            if action == "üöÄ ÊãìÈáè" and budget_factor < 1.0:
                action = "üìâ Èôç‰ª∑"

            final_factor = min(acos_factor, budget_factor)
            reason = " | ".join(reasons) if reasons else "-"
            rule = {
                "asin": asin,
                "sku": sku,
                "action": action,
                "reason": reason,
                "factor": final_factor,
                "tag": tag,
                "target_acos": target_acos,
            }
            asin_rules[(asin, sku)] = rule
            if not sku:
                asin_rules_by_asin[asin] = rule

        ads = pd.read_sql("SELECT ad_group_id, asin, sku, state FROM product_ads", conn)
        ad_groups = pd.read_sql("SELECT ad_group_id, campaign_id, state FROM ad_group_settings", conn)
        campaigns = list_sp_campaigns(session, headers, include_extended=True)

        whitelist = [w.strip() for w in get_auto_ai_campaign_whitelist() if str(w).strip()]
        allowed_campaign_ids = None
        campaign_name_map = {}
        if whitelist:
            whitelist_set = {str(w).strip() for w in whitelist if str(w).strip()}
            for c in campaigns:
                campaign_id = c.get("campaignId", c.get("campaign_id"))
                if campaign_id is None:
                    continue
                campaign_name_map[str(campaign_id)] = str(c.get("name", "")).strip()
            allowed_campaign_ids = {
                cid for cid, name in campaign_name_map.items() if cid in whitelist_set or name in whitelist_set
            }
            if not allowed_campaign_ids:
                ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                reason = f"Êú™ÂåπÈÖçÂà∞ÁôΩÂêçÂçïÊ¥ªÂä®: {', '.join(whitelist)}"
                logs.append(
                    {
                        "Êó∂Èó¥": ts,
                        "ÂπøÂëä": "Á≥ªÁªü",
                        "Á±ªÂûã": "Ëá™Âä®È©æÈ©∂",
                        "Âä®‰Ωú": "ÁôΩÂêçÂçïËøáÊª§",
                        "Âéü‰ª∑": 0,
                        "Êñ∞‰ª∑": 0,
                        "ÁêÜÁî±": reason,
                    }
                )
                with db_write_lock():
                    conn.execute(
                        "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                        (ts, "Á≥ªÁªü", "ÁôΩÂêçÂçïËøáÊª§", 0, 0, reason, "Â§±Ë¥•"),
                    )
                    conn.commit()
                conn.close()
                return logs

        if whitelist and campaigns:
            desired_budget = max(MIN_BUDGET, float(get_auto_ai_campaign_daily_budget() or 0))
            for c in campaigns:
                campaign_id = c.get("campaignId", c.get("campaign_id"))
                if campaign_id is None:
                    continue
                campaign_id = str(campaign_id)
                if allowed_campaign_ids is not None and campaign_id not in allowed_campaign_ids:
                    continue
                budget_obj = c.get("budget", {})
                if not isinstance(budget_obj, dict):
                    budget_obj = {}
                current_budget = float(budget_obj.get("budget", c.get("budget", 0)) or 0)
                budget_type = budget_obj.get("budgetType", c.get("budgetType", "DAILY"))
                if abs(current_budget - desired_budget) < 0.01:
                    continue
                status = "Ê®°Êãü"
                if is_live_mode:
                    ok, _ = update_campaign_budget(session, headers, "SP", campaign_id, desired_budget, budget_type)
                    status = "Â∑≤ÊâßË°å" if ok else "Â§±Ë¥•"
                ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                reason = f"È¢ÑÁÆóË∞ÉÊï¥: ${current_budget:.2f} -> ${desired_budget:.2f}"
                logs.append(
                    {
                        "Êó∂Èó¥": ts,
                        "ÂπøÂëä": campaign_name_map.get(campaign_id, f"Ê¥ªÂä®:{campaign_id}"),
                        "Á±ªÂûã": "È¢ÑÁÆó",
                        "Âä®‰Ωú": "SP Ê¥ªÂä®È¢ÑÁÆó",
                        "Âéü‰ª∑": current_budget,
                        "Êñ∞‰ª∑": desired_budget,
                        "ÁêÜÁî±": reason,
                    }
                )
                with db_write_lock():
                    conn.execute(
                        "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                        (ts, f"Ê¥ªÂä®:{campaign_id}", "SP Ê¥ªÂä®È¢ÑÁÆó", current_budget, desired_budget, reason, status),
                    )
                    conn.commit()

        enabled_states = ["ENABLED", "ENABLED_WITH_PENDING_CHANGES"]
        ad_group_campaign = {}
        enabled_ad_groups = None
        if not ad_groups.empty:
            ad_groups["ad_group_id"] = ad_groups["ad_group_id"].fillna("").astype(str)
            ad_groups["campaign_id"] = ad_groups["campaign_id"].fillna("").astype(str)
            groups_state = ad_groups["state"].fillna("").astype(str).str.upper()
            ad_groups = ad_groups[(groups_state == "") | (groups_state.isin(enabled_states))]
            if allowed_campaign_ids is not None:
                ad_groups = ad_groups[ad_groups["campaign_id"].isin(allowed_campaign_ids)]
            ad_group_campaign = dict(zip(ad_groups["ad_group_id"], ad_groups["campaign_id"]))
            enabled_ad_groups = set(ad_groups["ad_group_id"].tolist())

        if not ads.empty:
            ads["asin"] = ads["asin"].fillna("").astype(str).str.strip()
            ads["sku"] = ads["sku"].fillna("").astype(str).str.strip()
            ads_state = ads["state"].fillna("").astype(str).str.upper()
            ads = ads[(ads_state == "") | (ads_state.isin(enabled_states))]

        ad_group_map = {}
        for ad_group_id, group in ads.groupby("ad_group_id"):
            if not ad_group_id:
                continue
            if enabled_ad_groups is not None and str(ad_group_id) not in enabled_ad_groups:
                continue
            asins = sorted({a for a in group["asin"].tolist() if a})
            if len(asins) != 1:
                continue
            asin = asins[0]
            skus = sorted({s for s in group["sku"].tolist() if s})
            rule = None
            if len(skus) == 1:
                rule = asin_rules.get((asin, skus[0])) or asin_rules_by_asin.get(asin)
            else:
                rule = asin_rules_by_asin.get(asin)
            if not rule:
                continue
            ad_group_map[str(ad_group_id)] = rule

        ad_group_campaign = dict(zip(ad_groups["ad_group_id"], ad_groups["campaign_id"]))
        keywords = list_sp_keywords(session, headers)
        targets = list_sp_targets(session, headers)
        campaigns_for_placement = campaigns
        if allowed_campaign_ids is not None:
            campaigns_for_placement = [
                c
                for c in campaigns
                if str(c.get("campaignId", c.get("campaign_id")) or "") in allowed_campaign_ids
            ]

        keyword_updates = []
        target_updates = []
        rule_stats = {}

        for rule in ad_group_map.values():
            key = (rule["asin"], rule["sku"])
            rule_stats[key] = {"keywords": 0, "targets": 0, "placements": 0, "reason": rule["reason"]}

        for kw in keywords:
            keyword_id = kw.get("keywordId") or kw.get("keyword_id")
            if not keyword_id:
                continue
            ad_group_id = str(kw.get("adGroupId") or kw.get("ad_group_id") or "")
            rule = ad_group_map.get(ad_group_id)
            if not rule:
                continue
            state_flag = str(kw.get("state", "")).upper()
            if state_flag and state_flag not in enabled_states:
                continue
            old_bid = float(kw.get("bid", 0) or 0)
            if old_bid <= 0:
                continue
            if rule["action"] == "üõë Ê≠¢Êçü":
                new_bid = MIN_BID
            else:
                new_bid = max(MIN_BID, min(old_bid * rule["factor"], base_max_bid))
            if abs(new_bid - old_bid) < 0.01:
                continue
            keyword_updates.append({"keywordId": str(keyword_id), "bid": round(new_bid, 2)})
            rule_stats[(rule["asin"], rule["sku"])]["keywords"] += 1

        for tg in targets:
            id_key = "targetId"
            target_id = tg.get("targetId") or tg.get("target_id")
            if not target_id:
                id_key = "targetingClauseId"
                target_id = tg.get("targetingClauseId") or tg.get("targeting_clause_id")
            if not target_id:
                continue
            ad_group_id = str(tg.get("adGroupId") or tg.get("ad_group_id") or "")
            rule = ad_group_map.get(ad_group_id)
            if not rule:
                continue
            state_flag = str(tg.get("state", "")).upper()
            if state_flag and state_flag not in enabled_states:
                continue
            old_bid = float(tg.get("bid", 0) or 0)
            if old_bid <= 0:
                continue
            if rule["action"] == "üõë Ê≠¢Êçü":
                new_bid = MIN_BID
            else:
                new_bid = max(MIN_BID, min(old_bid * rule["factor"], base_max_bid))
            if abs(new_bid - old_bid) < 0.01:
                continue
            target_updates.append({id_key: str(target_id), "bid": round(new_bid, 2)})
            rule_stats[(rule["asin"], rule["sku"])]["targets"] += 1

        placement_updates = []
        placement_predicates = ["placementTop", "placementProductPage", "placementRestOfSearch"]
        defaults_up = {"placementTop": 20, "placementProductPage": 10, "placementRestOfSearch": 5}
        campaign_bids = {}
        for c in campaigns_for_placement:
            campaign_id = c.get("campaignId", c.get("campaign_id"))
            if not campaign_id:
                continue
            bidding = c.get("bidding") or {}
            adjustments = bidding.get("adjustments") or []
            current = {}
            for adj in adjustments:
                predicate = adj.get("predicate")
                pct = adj.get("percentage")
                if predicate:
                    current[predicate] = pct if pct is not None else 0
            campaign_bids[str(campaign_id)] = current

        campaign_rule_keys = {}
        for ad_group_id, rule in ad_group_map.items():
            campaign_id = ad_group_campaign.get(ad_group_id, "")
            if not campaign_id:
                continue
            key = (rule["asin"], rule["sku"])
            campaign_rule_keys.setdefault(campaign_id, set()).add(key)

        for campaign_id, keys in campaign_rule_keys.items():
            if len(keys) != 1:
                continue
            rule_key = next(iter(keys))
            rule = asin_rules.get(rule_key)
            if not rule:
                continue
            if rule["action"] == "‰øùÊåÅ" and rule["factor"] == 1.0:
                continue
            current = campaign_bids.get(str(campaign_id), {})
            adjustments = []
            for predicate in placement_predicates:
                current_pct = int(current.get(predicate, 0) or 0)
                if rule["action"] == "üõë Ê≠¢Êçü":
                    new_pct = 0
                else:
                    if current_pct > 0:
                        new_pct = int(round(current_pct * rule["factor"]))
                    else:
                        new_pct = defaults_up[predicate] if rule["factor"] > 1.0 else 0
                new_pct = max(0, min(new_pct, 900))
                if current_pct == new_pct:
                    continue
                adjustments.append({"predicate": predicate, "percentage": new_pct})
            if not adjustments:
                continue
            placement_updates.append({"campaignId": str(campaign_id), "bidding": {"adjustments": adjustments}})
            rule_stats[rule_key]["placements"] += 1

        keyword_ok = True
        target_ok = True
        placement_ok = True
        if is_live_mode:
            for batch in _chunked(keyword_updates, 100):
                ok, _ = update_sp_keyword_bids(session, headers, batch)
                if not ok:
                    keyword_ok = False
            for batch in _chunked(target_updates, 100):
                ok, _ = update_sp_target_bids(session, headers, batch)
                if not ok:
                    target_ok = False
            for update in placement_updates:
                ok, _ = update_sp_campaign_bidding(session, headers, [update])
                if not ok and len(update["bidding"]["adjustments"]) > 1:
                    filtered = [
                        adj for adj in update["bidding"]["adjustments"] if adj["predicate"] != "placementRestOfSearch"
                    ]
                    if filtered:
                        ok, _ = update_sp_campaign_bidding(
                            session, headers, [{"campaignId": update["campaignId"], "bidding": {"adjustments": filtered}}]
                        )
                if not ok:
                    placement_ok = False

        ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        with db_write_lock():
            for rule_key, stats in rule_stats.items():
                total_ops = stats["keywords"] + stats["targets"] + stats["placements"]
                if total_ops <= 0:
                    continue
                status = "Ê®°Êãü"
                if is_live_mode:
                    if keyword_ok and target_ok and placement_ok:
                        status = "Â∑≤ÊâßË°å"
                    elif keyword_ok or target_ok or placement_ok:
                        status = "ÈÉ®ÂàÜÂ§±Ë¥•"
                    else:
                        status = "Â§±Ë¥•"
                asin, sku = rule_key
                reason = stats["reason"]
                if live_note:
                    reason = f"{reason}{live_note}"
                reason = f"{reason} | ÂÖ≥ÈîÆËØç{stats['keywords']} ÊäïÊîæ{stats['targets']} ÂπøÂëä‰Ωç{stats['placements']}"
                action_label = "SP Á´û‰ª∑Ë∞ÉÊï¥"
                logs.append(
                    {
                        "Êó∂Èó¥": ts,
                        "ÂπøÂëä": f"ASIN:{asin}",
                        "Á±ªÂûã": "ASIN",
                        "Âä®‰Ωú": action_label,
                        "Âéü‰ª∑": 0,
                        "Êñ∞‰ª∑": 0,
                        "ÁêÜÁî±": reason,
                    }
                )
                conn.execute(
                    "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                    (ts, f"ASIN:{asin}", action_label, 0, 0, reason, status),
                )
            conn.commit()

        # === Ëá™Âä®Âê¶ËØçÔºöÂü∫‰∫éÊêúÁ¥¢ËØçË°®Áé∞ ===
        auto_neg_cfg = _get_auto_negative_config(auto_negative_config)
        if auto_neg_cfg["enabled"]:
            level = auto_neg_cfg.get("level", "adgroup")
            match_type = _normalize_negative_match(auto_neg_cfg.get("match", "NEGATIVE_EXACT"))
            spend_threshold = float(auto_neg_cfg.get("spend", 3.0) or 0)
            clicks_threshold = int(auto_neg_cfg.get("clicks", 8) or 0)
            acos_mult = float(auto_neg_cfg.get("acos_mult", 1.5) or 1.0)
            days = int(auto_neg_cfg.get("days", 7) or 7)
            days = max(1, min(days, 30))
            protect_terms = auto_neg_cfg.get("protect_terms")
            if not protect_terms:
                protect_terms = get_system_value(AUTO_NEGATIVE_PROTECT_KEY)
            protect_mode = auto_neg_cfg.get("protect_mode") or get_system_value(
                AUTO_NEGATIVE_PROTECT_MODE_KEY
            ) or "contains"
            protect_terms = _parse_protect_terms(protect_terms)
            if str(protect_mode).lower() == "exact":
                protect_terms = set(protect_terms)

            end_date = (today - timedelta(days=1)).strftime("%Y-%m-%d")
            start_date = (today - timedelta(days=days)).strftime("%Y-%m-%d")

            data = None
            sales_keys = []
            orders_keys = []
            pending = _load_pending_report()

            if (
                pending
                and pending.get("report_id")
                and pending.get("start") == start_date
                and pending.get("end") == end_date
            ):
                sales_keys = pending.get("sales_keys") or []
                orders_keys = pending.get("orders_keys") or []
                data, err = _check_report_once(session, headers, pending.get("report_id"))
                if err == "pending":
                    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    reason = f"Âê¶ËØçÊä•ÂëäÁîüÊàê‰∏≠: {pending.get('report_id')}"
                    logs.append(
                        {
                            "Êó∂Èó¥": ts,
                            "ÂπøÂëä": "Á≥ªÁªü",
                            "Á±ªÂûã": "Âê¶ËØç",
                            "Âä®‰Ωú": "SP Ëá™Âä®Âê¶ËØç",
                            "Âéü‰ª∑": 0,
                            "Êñ∞‰ª∑": 0,
                            "ÁêÜÁî±": reason,
                        }
                    )
                    with db_write_lock():
                        conn.execute(
                            "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                            (ts, "Á≥ªÁªü", "SP Ëá™Âä®Âê¶ËØç", 0, 0, reason, "Ê®°Êãü"),
                        )
                        conn.commit()
                    data = None
                elif err:
                    _clear_pending_report()
                    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    reason = f"Âê¶ËØçÊä•ÂëäÂ§±Ë¥•: {err}"
                    logs.append(
                        {
                            "Êó∂Èó¥": ts,
                            "ÂπøÂëä": "Á≥ªÁªü",
                            "Á±ªÂûã": "Âê¶ËØç",
                            "Âä®‰Ωú": "SP Ëá™Âä®Âê¶ËØç",
                            "Âéü‰ª∑": 0,
                            "Êñ∞‰ª∑": 0,
                            "ÁêÜÁî±": reason,
                        }
                    )
                    with db_write_lock():
                        conn.execute(
                            "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                            (ts, "Á≥ªÁªü", "SP Ëá™Âä®Âê¶ËØç", 0, 0, reason, "Â§±Ë¥•"),
                        )
                        conn.commit()
                    data = None
                else:
                    _clear_pending_report()
            else:
                if pending:
                    _clear_pending_report()
                report_id, sales_keys, orders_keys, err = _fetch_search_term_report(
                    session, headers, start_date, end_date
                )
                if err:
                    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    reason = f"Âê¶ËØçÊä•ÂëäÂ§±Ë¥•: {err}"
                    logs.append(
                        {
                            "Êó∂Èó¥": ts,
                            "ÂπøÂëä": "Á≥ªÁªü",
                            "Á±ªÂûã": "Âê¶ËØç",
                            "Âä®‰Ωú": "SP Ëá™Âä®Âê¶ËØç",
                            "Âéü‰ª∑": 0,
                            "Êñ∞‰ª∑": 0,
                            "ÁêÜÁî±": reason,
                        }
                    )
                    with db_write_lock():
                        conn.execute(
                            "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                            (ts, "Á≥ªÁªü", "SP Ëá™Âä®Âê¶ËØç", 0, 0, reason, "Â§±Ë¥•"),
                        )
                        conn.commit()
                    data = None
                else:
                    data, err = _wait_for_report(session, headers, report_id, max_polls=10)
                    if err == "pending":
                        _save_pending_report(report_id, start_date, end_date, sales_keys, orders_keys)
                        ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        reason = f"Âê¶ËØçÊä•ÂëäÁîüÊàê‰∏≠: {report_id}"
                        logs.append(
                            {
                                "Êó∂Èó¥": ts,
                                "ÂπøÂëä": "Á≥ªÁªü",
                                "Á±ªÂûã": "Âê¶ËØç",
                                "Âä®‰Ωú": "SP Ëá™Âä®Âê¶ËØç",
                                "Âéü‰ª∑": 0,
                                "Êñ∞‰ª∑": 0,
                                "ÁêÜÁî±": reason,
                            }
                        )
                        with db_write_lock():
                            conn.execute(
                                "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                                (ts, "Á≥ªÁªü", "SP Ëá™Âä®Âê¶ËØç", 0, 0, reason, "Ê®°Êãü"),
                            )
                            conn.commit()
                        data = None
                    elif err:
                        ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        reason = f"Âê¶ËØçÊä•ÂëäÂ§±Ë¥•: {err}"
                        logs.append(
                            {
                                "Êó∂Èó¥": ts,
                                "ÂπøÂëä": "Á≥ªÁªü",
                                "Á±ªÂûã": "Âê¶ËØç",
                                "Âä®‰Ωú": "SP Ëá™Âä®Âê¶ËØç",
                                "Âéü‰ª∑": 0,
                                "Êñ∞‰ª∑": 0,
                                "ÁêÜÁî±": reason,
                            }
                        )
                        with db_write_lock():
                            conn.execute(
                                "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                                (ts, "Á≥ªÁªü", "SP Ëá™Âä®Âê¶ËØç", 0, 0, reason, "Â§±Ë¥•"),
                            )
                            conn.commit()
                        data = None
                    else:
                        _clear_pending_report()

            if data is None or data.empty:
                if data is not None and data.empty:
                    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    reason = "Âê¶ËØçÊä•Âëä‰∏∫Á©∫"
                    logs.append(
                        {
                            "Êó∂Èó¥": ts,
                            "ÂπøÂëä": "Á≥ªÁªü",
                            "Á±ªÂûã": "Âê¶ËØç",
                            "Âä®‰Ωú": "SP Ëá™Âä®Âê¶ËØç",
                            "Âéü‰ª∑": 0,
                            "Êñ∞‰ª∑": 0,
                            "ÁêÜÁî±": reason,
                        }
                    )
                    with db_write_lock():
                        conn.execute(
                            "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                            (ts, "Á≥ªÁªü", "SP Ëá™Âä®Âê¶ËØç", 0, 0, reason, "Ê®°Êãü" if not is_live_mode else "Â§±Ë¥•"),
                        )
                        conn.commit()
            else:
                data.columns = [c.lower() for c in data.columns]
                sales_candidates = [k.lower() for k in (sales_keys or [])] + SEARCH_SALES_KEYS
                order_candidates = [k.lower() for k in (orders_keys or [])] + SEARCH_ORDER_KEYS

                records = []
                for _, row in data.iterrows():
                    search_term = row.get("searchterm") or row.get("search_term")
                    if not search_term:
                        continue
                    campaign_id = row.get("campaignid") or row.get("campaign_id")
                    ad_group_id = row.get("adgroupid") or row.get("ad_group_id")
                    if not ad_group_id:
                        continue
                    cost = get_row_value(row, SEARCH_COST_KEYS, 0)
                    sales = get_row_value(row, sales_candidates, 0)
                    orders = get_row_value(row, order_candidates, 0)
                    clicks = get_row_value(row, ["clicks"], 0)
                    impressions = get_row_value(row, ["impressions"], 0)
                    records.append(
                        {
                            "campaign_id": str(campaign_id or ""),
                            "ad_group_id": str(ad_group_id),
                            "search_term": str(search_term).strip(),
                            "cost": float(cost or 0),
                            "sales": float(sales or 0),
                            "orders": float(orders or 0),
                            "clicks": float(clicks or 0),
                            "impressions": float(impressions or 0),
                        }
                    )

                if records:
                    df_terms = pd.DataFrame(records)
                    agg = (
                        df_terms.groupby(["campaign_id", "ad_group_id", "search_term"], as_index=False)[
                            ["cost", "sales", "orders", "clicks", "impressions"]
                        ]
                        .sum()
                        .reset_index(drop=True)
                    )
                else:
                    agg = pd.DataFrame()

                if agg.empty:
                    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    reason = "Âê¶ËØçÊä•ÂëäÊó†ÊúâÊïàÊï∞ÊçÆ"
                    logs.append(
                        {
                            "Êó∂Èó¥": ts,
                            "ÂπøÂëä": "Á≥ªÁªü",
                            "Á±ªÂûã": "Âê¶ËØç",
                            "Âä®‰Ωú": "SP Ëá™Âä®Âê¶ËØç",
                            "Âéü‰ª∑": 0,
                            "Êñ∞‰ª∑": 0,
                            "ÁêÜÁî±": reason,
                        }
                    )
                    with db_write_lock():
                        conn.execute(
                            "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                            (ts, "Á≥ªÁªü", "SP Ëá™Âä®Âê¶ËØç", 0, 0, reason, "Ê®°Êãü" if not is_live_mode else "Â§±Ë¥•"),
                        )
                        conn.commit()
                else:
                    # Â∑≤Â≠òÂú®Âê¶ËØçÈõÜÂêà
                    existing = set()
                    if level == "campaign":
                        items = list_sp_campaign_negative_keywords(session, headers)
                        for item in items:
                            key = (
                                str(item.get("campaignId") or ""),
                                "",
                                str(item.get("keywordText") or "").strip().lower(),
                                _normalize_negative_match(item.get("matchType")),
                            )
                            existing.add(key)
                    else:
                        items = list_sp_negative_keywords(session, headers)
                        for item in items:
                            key = (
                                str(item.get("campaignId") or ""),
                                str(item.get("adGroupId") or ""),
                                str(item.get("keywordText") or "").strip().lower(),
                                _normalize_negative_match(item.get("matchType")),
                            )
                            existing.add(key)

                    payloads = []
                    ai_records = []
                    for _, r in agg.iterrows():
                        ad_group_id = r.get("ad_group_id")
                        if ad_group_id is None or (isinstance(ad_group_id, float) and pd.isna(ad_group_id)):
                            ad_group_id = ""
                        ad_group_id = str(ad_group_id or "").strip()
                        if not ad_group_id:
                            continue
                        if enabled_ad_groups is not None and ad_group_id not in enabled_ad_groups:
                            continue
                        rule = ad_group_map.get(ad_group_id)
                        if not rule:
                            rule = {"target_acos": base_target_acos}
                        term = str(r["search_term"]).strip()
                        if not term:
                            continue
                        if _is_protected_term(term, protect_terms, protect_mode):
                            continue
                        cost = float(r["cost"] or 0)
                        sales = float(r["sales"] or 0)
                        clicks = float(r["clicks"] or 0)
                        orders = float(r.get("orders") or 0)
                        if cost < spend_threshold or clicks < clicks_threshold:
                            continue
                        target_acos = float(rule.get("target_acos", base_target_acos) or base_target_acos)
                        term_acos = cost / sales if sales > 0 else None
                        action = None
                        reason_detail = ""
                        if sales <= 0:
                            action = "Êó†ËΩ¨ÂåñÈ´òËä±Ë¥π"
                            reason_detail = f"{action}: Ëä±Ë¥π${cost:.2f} ÁÇπÂáª{int(clicks)}"
                        elif term_acos is not None and term_acos > (target_acos / 100.0 * acos_mult):
                            action = "ACOSËøáÈ´ò"
                            reason_detail = (
                                f"{action}: {term_acos*100:.1f}% > ÁõÆÊ†á{target_acos:.1f}%√ó{acos_mult}"
                            )
                        if not action:
                            continue
                        campaign_id = r.get("campaign_id")
                        if campaign_id is None or (isinstance(campaign_id, float) and pd.isna(campaign_id)):
                            campaign_id = ""
                        campaign_id = str(campaign_id or "")
                        if not campaign_id:
                            campaign_id = str(ad_group_campaign.get(ad_group_id, "") or "")
                        if not campaign_id:
                            continue
                        key = (
                            campaign_id,
                            "" if level == "campaign" else ad_group_id,
                            term.lower(),
                            match_type,
                        )
                        if key in existing:
                            continue
                        item = {
                            "campaignId": campaign_id,
                            "keywordText": term,
                            "matchType": match_type,
                            "state": "ENABLED",
                        }
                        if level == "adgroup":
                            item["adGroupId"] = ad_group_id
                        payloads.append(item)
                        existing.add(key)
                        ai_records.append(
                            {
                                "campaign_id": str(campaign_id or ""),
                                "ad_group_id": "" if level == "campaign" else str(ad_group_id or ""),
                                "keyword_text": str(term),
                                "match_type": str(match_type),
                                "level": level,
                                "source": "AI",
                                "status": "pending" if is_live_mode else "dry_run",
                                "reason": reason_detail or action,
                                "cost": cost,
                                "sales": sales,
                                "orders": orders,
                                "clicks": clicks,
                            }
                        )
                    if ai_records:
                        save_auto_negative_keywords(ai_records)

                    created = 0
                    status = "Ê®°Êãü"
                    if payloads and is_live_mode:
                        ok_all = True
                        for batch in _chunked(payloads, 100):
                            ok, _ = create_sp_negative_keywords(
                                session, headers, batch, campaign_level=(level == "campaign")
                            )
                            if not ok:
                                ok_all = False
                        if ok_all:
                            status = "Â∑≤ÊâßË°å"
                            update_auto_negative_status(ai_records, "created")
                        else:
                            status = "ÈÉ®ÂàÜÂ§±Ë¥•"
                            update_auto_negative_status(ai_records, "partial")
                    elif payloads:
                        status = "Ê®°Êãü"
                        update_auto_negative_status(ai_records, "dry_run")

                    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    reason = f"Ëá™Âä®Âê¶ËØç {len(payloads)} Êù° | ÈòàÂÄº Ëä±Ë¥π‚â•{spend_threshold} ÁÇπÂáª‚â•{clicks_threshold} ACOS√ó{acos_mult}"
                    logs.append(
                        {
                            "Êó∂Èó¥": ts,
                            "ÂπøÂëä": "Á≥ªÁªü",
                            "Á±ªÂûã": "Âê¶ËØç",
                            "Âä®‰Ωú": "SP Ëá™Âä®Âê¶ËØç",
                            "Âéü‰ª∑": 0,
                            "Êñ∞‰ª∑": 0,
                            "ÁêÜÁî±": reason,
                        }
                    )
                    with db_write_lock():
                        conn.execute(
                            "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                            (ts, "Á≥ªÁªü", "SP Ëá™Âä®Âê¶ËØç", 0, 0, reason, status),
                        )
                        conn.commit()
                    set_system_value(AUTO_NEGATIVE_LAST_RUN_KEY, ts)

        # === Ëá™Âä®ÊäïËØç/ÊãìËØçÔºöÂü∫‰∫éÊêúÁ¥¢ËØçË°®Áé∞ ===
        auto_expand_enabled = bool(allowed_campaign_ids) if whitelist else False
        if auto_expand_enabled:
            expand_days = 7
            expand_min_clicks = 4
            expand_min_orders = 1
            expand_strong_clicks = 6
            expand_strong_orders = 2
            expand_max_new = None
            expand_acos_factor = 1.2
            expand_strong_acos_factor = 0.8
            expand_allow_broad = True

            end_date = (today - timedelta(days=1)).strftime("%Y-%m-%d")
            start_date = (today - timedelta(days=expand_days)).strftime("%Y-%m-%d")

            data = None
            sales_keys = []
            orders_keys = []
            pending = _load_pending_report(AUTO_KEYWORD_PENDING_KEY)

            if (
                pending
                and pending.get("report_id")
                and pending.get("start") == start_date
                and pending.get("end") == end_date
            ):
                sales_keys = pending.get("sales_keys") or []
                orders_keys = pending.get("orders_keys") or []
                data, err = _check_report_once(session, headers, pending.get("report_id"))
                if err == "pending":
                    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    reason = f"ÊäïËØçÊä•ÂëäÁîüÊàê‰∏≠: {pending.get('report_id')}"
                    logs.append(
                        {
                            "Êó∂Èó¥": ts,
                            "ÂπøÂëä": "Á≥ªÁªü",
                            "Á±ªÂûã": "ÊäïËØç",
                            "Âä®‰Ωú": "SP Ëá™Âä®ÊäïËØç",
                            "ÂéüÂÄº": 0,
                            "Êñ∞ÂÄº": 0,
                            "ÂéüÂõ†": reason,
                        }
                    )
                    with db_write_lock():
                        conn.execute(
                            "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                            (ts, "Á≥ªÁªü", "SP Ëá™Âä®ÊäïËØç", 0, 0, reason, "Ê®°Êãü"),
                        )
                        conn.commit()
                    data = None
                elif err:
                    _clear_pending_report(AUTO_KEYWORD_PENDING_KEY)
                    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    reason = f"ÊäïËØçÊä•ÂëäÂ§±Ë¥•: {err}"
                    logs.append(
                        {
                            "Êó∂Èó¥": ts,
                            "ÂπøÂëä": "Á≥ªÁªü",
                            "Á±ªÂûã": "ÊäïËØç",
                            "Âä®‰Ωú": "SP Ëá™Âä®ÊäïËØç",
                            "ÂéüÂÄº": 0,
                            "Êñ∞ÂÄº": 0,
                            "ÂéüÂõ†": reason,
                        }
                    )
                    with db_write_lock():
                        conn.execute(
                            "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                            (ts, "Á≥ªÁªü", "SP Ëá™Âä®ÊäïËØç", 0, 0, reason, "Â§±Ë¥•"),
                        )
                        conn.commit()
                    data = None
                else:
                    _clear_pending_report(AUTO_KEYWORD_PENDING_KEY)
            else:
                if pending:
                    _clear_pending_report(AUTO_KEYWORD_PENDING_KEY)
                report_id, sales_keys, orders_keys, err = _fetch_search_term_report(
                    session, headers, start_date, end_date
                )
                if err:
                    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    reason = f"ÊäïËØçÊä•ÂëäÂ§±Ë¥•: {err}"
                    logs.append(
                        {
                            "Êó∂Èó¥": ts,
                            "ÂπøÂëä": "Á≥ªÁªü",
                            "Á±ªÂûã": "ÊäïËØç",
                            "Âä®‰Ωú": "SP Ëá™Âä®ÊäïËØç",
                            "ÂéüÂÄº": 0,
                            "Êñ∞ÂÄº": 0,
                            "ÂéüÂõ†": reason,
                        }
                    )
                    with db_write_lock():
                        conn.execute(
                            "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                            (ts, "Á≥ªÁªü", "SP Ëá™Âä®ÊäïËØç", 0, 0, reason, "Â§±Ë¥•"),
                        )
                        conn.commit()
                    data = None
                else:
                    data, err = _wait_for_report(session, headers, report_id, max_polls=10)
                    if err == "pending":
                        _save_pending_report(
                            report_id, start_date, end_date, sales_keys, orders_keys, key=AUTO_KEYWORD_PENDING_KEY
                        )
                        ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        reason = f"ÊäïËØçÊä•ÂëäÁîüÊàê‰∏≠: {report_id}"
                        logs.append(
                            {
                                "Êó∂Èó¥": ts,
                                "ÂπøÂëä": "Á≥ªÁªü",
                                "Á±ªÂûã": "ÊäïËØç",
                                "Âä®‰Ωú": "SP Ëá™Âä®ÊäïËØç",
                                "ÂéüÂÄº": 0,
                                "Êñ∞ÂÄº": 0,
                                "ÂéüÂõ†": reason,
                            }
                        )
                        with db_write_lock():
                            conn.execute(
                                "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                                (ts, "Á≥ªÁªü", "SP Ëá™Âä®ÊäïËØç", 0, 0, reason, "Ê®°Êãü"),
                            )
                            conn.commit()
                        data = None
                    elif err:
                        ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        reason = f"ÊäïËØçÊä•ÂëäÂ§±Ë¥•: {err}"
                        logs.append(
                            {
                                "Êó∂Èó¥": ts,
                                "ÂπøÂëä": "Á≥ªÁªü",
                                "Á±ªÂûã": "ÊäïËØç",
                                "Âä®‰Ωú": "SP Ëá™Âä®ÊäïËØç",
                                "ÂéüÂÄº": 0,
                                "Êñ∞ÂÄº": 0,
                                "ÂéüÂõ†": reason,
                            }
                        )
                        with db_write_lock():
                            conn.execute(
                                "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                                (ts, "Á≥ªÁªü", "SP Ëá™Âä®ÊäïËØç", 0, 0, reason, "Â§±Ë¥•"),
                            )
                            conn.commit()
                        data = None
                    else:
                        _clear_pending_report(AUTO_KEYWORD_PENDING_KEY)

            if data is None or data.empty:
                if data is not None and data.empty:
                    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    reason = "ÊäïËØçÊä•Âëä‰∏∫Á©∫"
                    logs.append(
                        {
                            "Êó∂Èó¥": ts,
                            "ÂπøÂëä": "Á≥ªÁªü",
                            "Á±ªÂûã": "ÊäïËØç",
                            "Âä®‰Ωú": "SP Ëá™Âä®ÊäïËØç",
                            "ÂéüÂÄº": 0,
                            "Êñ∞ÂÄº": 0,
                            "ÂéüÂõ†": reason,
                        }
                    )
                    with db_write_lock():
                        conn.execute(
                            "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                            (ts, "Á≥ªÁªü", "SP Ëá™Âä®ÊäïËØç", 0, 0, reason, "Ê®°Êãü" if not is_live_mode else "Â§±Ë¥•"),
                        )
                        conn.commit()
            else:
                data.columns = [c.lower() for c in data.columns]
                sales_candidates = [k.lower() for k in (sales_keys or [])] + SEARCH_SALES_KEYS
                order_candidates = [k.lower() for k in (orders_keys or [])] + SEARCH_ORDER_KEYS

                records = []
                for _, row in data.iterrows():
                    search_term = row.get("searchterm") or row.get("search_term")
                    if not search_term:
                        continue
                    ad_group_id = row.get("adgroupid") or row.get("ad_group_id")
                    if not ad_group_id:
                        continue
                    campaign_id = row.get("campaignid") or row.get("campaign_id")
                    if campaign_id is None or (isinstance(campaign_id, float) and pd.isna(campaign_id)):
                        campaign_id = ""
                    campaign_id = str(campaign_id or "")
                    ad_group_id = str(ad_group_id or "")
                    if not campaign_id:
                        campaign_id = str(ad_group_campaign.get(ad_group_id, "") or "")
                    if not campaign_id:
                        continue
                    if allowed_campaign_ids is not None and campaign_id not in allowed_campaign_ids:
                        continue
                    if enabled_ad_groups is not None and ad_group_id not in enabled_ad_groups:
                        continue
                    cost = get_row_value(row, SEARCH_COST_KEYS, 0)
                    sales = get_row_value(row, sales_candidates, 0)
                    orders = get_row_value(row, order_candidates, 0)
                    clicks = get_row_value(row, ["clicks"], 0)
                    impressions = get_row_value(row, ["impressions"], 0)
                    records.append(
                        {
                            "campaign_id": str(campaign_id or ""),
                            "ad_group_id": str(ad_group_id),
                            "search_term": str(search_term).strip(),
                            "cost": float(cost or 0),
                            "sales": float(sales or 0),
                            "orders": float(orders or 0),
                            "clicks": float(clicks or 0),
                            "impressions": float(impressions or 0),
                        }
                    )

                if records:
                    df_terms = pd.DataFrame(records)
                    agg = (
                        df_terms.groupby(["campaign_id", "ad_group_id", "search_term"], as_index=False)[
                            ["cost", "sales", "orders", "clicks", "impressions"]
                        ]
                        .sum()
                        .reset_index(drop=True)
                    )
                else:
                    agg = pd.DataFrame()

                if agg.empty:
                    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    reason = "ÊäïËØçÊä•ÂëäÊó†ÊúâÊïàÊï∞ÊçÆ"
                    logs.append(
                        {
                            "Êó∂Èó¥": ts,
                            "ÂπøÂëä": "Á≥ªÁªü",
                            "Á±ªÂûã": "ÊäïËØç",
                            "Âä®‰Ωú": "SP Ëá™Âä®ÊäïËØç",
                            "ÂéüÂÄº": 0,
                            "Êñ∞ÂÄº": 0,
                            "ÂéüÂõ†": reason,
                        }
                    )
                    with db_write_lock():
                        conn.execute(
                            "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                            (ts, "Á≥ªÁªü", "SP Ëá™Âä®ÊäïËØç", 0, 0, reason, "Ê®°Êãü" if not is_live_mode else "Â§±Ë¥•"),
                        )
                        conn.commit()
                else:
                    existing_kw = set()
                    existing_term_any = set()
                    for kw in keywords:
                        keyword_text = str(kw.get("keywordText") or "").strip()
                        if not keyword_text:
                            continue
                        campaign_id = str(kw.get("campaignId") or kw.get("campaign_id") or "")
                        ad_group_id = str(kw.get("adGroupId") or kw.get("ad_group_id") or "")
                        if not campaign_id or not ad_group_id:
                            continue
                        match_type = _normalize_positive_match(kw.get("matchType"))
                        if not match_type:
                            continue
                        existing_kw.add((campaign_id, ad_group_id, keyword_text.lower(), match_type))
                        existing_term_any.add((campaign_id, ad_group_id, keyword_text.lower()))

                    neg_terms = set()
                    items = list_sp_campaign_negative_keywords(session, headers)
                    for item in items:
                        term = str(item.get("keywordText") or "").strip().lower()
                        if not term:
                            continue
                        neg_terms.add((str(item.get("campaignId") or ""), "", term))
                    items = list_sp_negative_keywords(session, headers)
                    for item in items:
                        term = str(item.get("keywordText") or "").strip().lower()
                        if not term:
                            continue
                        neg_terms.add(
                            (
                                str(item.get("campaignId") or ""),
                                str(item.get("adGroupId") or ""),
                                term,
                            )
                        )

                    payloads = []
                    action_rows = []
                    agg_sorted = agg.sort_values(["orders", "sales", "clicks"], ascending=False)
                    for _, r in agg_sorted.iterrows():
                        if expand_max_new is not None and len(payloads) >= expand_max_new:
                            break
                        term = str(r.get("search_term") or "").strip()
                        if not term:
                            continue
                        if _is_asin_term(term):
                            continue
                        term_lower = term.lower()
                        campaign_id = str(r.get("campaign_id") or "")
                        ad_group_id = str(r.get("ad_group_id") or "")
                        if not campaign_id:
                            campaign_id = str(ad_group_campaign.get(ad_group_id, "") or "")
                        if not campaign_id or not ad_group_id:
                            continue
                        if (campaign_id, ad_group_id, term_lower) in existing_term_any:
                            continue
                        if (campaign_id, "", term_lower) in neg_terms or (campaign_id, ad_group_id, term_lower) in neg_terms:
                            continue
                        cost = float(r.get("cost") or 0)
                        sales = float(r.get("sales") or 0)
                        orders = float(r.get("orders") or 0)
                        clicks = float(r.get("clicks") or 0)
                        if sales <= 0 or orders < expand_min_orders or clicks < expand_min_clicks:
                            continue
                        target_acos = base_target_acos
                        rule = ad_group_map.get(ad_group_id)
                        if rule and rule.get("target_acos"):
                            target_acos = float(rule.get("target_acos") or base_target_acos)
                        acos_pct = cost / sales * 100 if sales > 0 else 0
                        if acos_pct > target_acos * expand_acos_factor:
                            continue
                        strong = (
                            orders >= expand_strong_orders
                            and clicks >= expand_strong_clicks
                            and acos_pct <= target_acos * expand_strong_acos_factor
                        )
                        match_types = ["EXACT"]
                        if expand_allow_broad:
                            match_types.append("BROAD")
                        if strong:
                            match_types.append("PHRASE")
                        avg_cpc = cost / clicks if clicks > 0 else base_max_bid * 0.6
                        base_bid = max(MIN_BID, min(base_max_bid, avg_cpc * (1.2 if strong else 1.1)))
                        for match_type in match_types:
                            if expand_max_new is not None and len(payloads) >= expand_max_new:
                                break
                            key = (campaign_id, ad_group_id, term_lower, match_type)
                            if key in existing_kw:
                                continue
                            payloads.append(
                                {
                                    "campaignId": campaign_id,
                                    "adGroupId": ad_group_id,
                                    "state": "ENABLED",
                                    "keywordText": term,
                                    "matchType": match_type,
                                    "bid": round(base_bid, 2),
                                }
                            )
                            existing_kw.add(key)
                            action_rows.append(
                                {
                                    "term": term,
                                    "campaign_id": campaign_id,
                                    "ad_group_id": ad_group_id,
                                    "bid": round(base_bid, 2),
                                    "match_type": match_type,
                                    "acos": acos_pct,
                                    "orders": orders,
                                    "clicks": clicks,
                                }
                            )

                    if payloads:
                        ok_all = True
                        status = "Ê®°Êãü"
                        if is_live_mode:
                            for batch in _chunked(payloads, 100):
                                ok, _ = create_sp_keywords(session, headers, batch)
                                if not ok:
                                    ok_all = False
                            status = "Â∑≤ÊâßË°å" if ok_all else "ÈÉ®ÂàÜÂ§±Ë¥•"

                        ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        with db_write_lock():
                            for row in action_rows:
                                campaign_label = campaign_name_map.get(row["campaign_id"], row["campaign_id"])
                                reason = (
                                    f"ÊäïËØç: {row['match_type']} | {campaign_label}/{row['ad_group_id']} | "
                                    f"ACOS {row['acos']:.1f}% ÁÇπÂáª{int(row['clicks'])} ËÆ¢Âçï{int(row['orders'])}"
                                )
                                logs.append(
                                    {
                                        "Êó∂Èó¥": ts,
                                        "ÂπøÂëä": f"ÂÖ≥ÈîÆËØç:{row['term']}",
                                        "Á±ªÂûã": "ÊäïËØç",
                                        "Âä®‰Ωú": "SP Ëá™Âä®ÊäïËØç",
                                        "ÂéüÂÄº": 0,
                                        "Êñ∞ÂÄº": row["bid"],
                                        "ÂéüÂõ†": reason,
                                    }
                                )
                                conn.execute(
                                    "INSERT INTO automation_logs VALUES (?,?,?,?,?,?,?)",
                                    (
                                        ts,
                                        f"ÂÖ≥ÈîÆËØç:{row['term']}",
                                        "SP Ëá™Âä®ÊäïËØç",
                                        0,
                                        row["bid"],
                                        reason,
                                        status,
                                    ),
                                )
                            conn.commit()

    conn.commit()
    conn.close()
    return logs
